# VM as a Tool for Caching
# 虚拟内存作为缓存的工具

概念上而言，虚拟内存被组织为一个由存放在"磁盘"上的 N 个连续的字节大小的单元组成的数组。每字节都有一个唯一的虚拟地址，作为到数组的索引。
磁盘上数组的内容被缓存在主存中。和存储器层次结构中其他缓存一样，磁盘（较低层）上的数据被分割成块，这些块作为磁盘和主存（较高层）之间的传输单元。
VM 系统通过将虚拟内存分割为称为虚拟页（`Virtual Page`，VP）的大小固定的块来处理这个问题。每个虚拟页的大小为 P = 2 ^ p 字节。
类似地，物理内存被分割为物理页（`Physical Page`，PP），大小也为 P 字节（物理页也被称为页帧（`page frame`））。

在任意时刻，虚拟页面的集合都分为三个不相交的子集：

 - **未分配的**：VM 系统还未分配（或者创建）的页。未分配的块没有任何数据和它们相关联，因此也就不占用任何磁盘空间。
 - **缓存的**：当前已缓存在物理内存中的已分配页。
 - **未缓存的**：未缓存在物理内存中的已分配页。

====================================================================================================
在虚拟内存系统（VM）中，虚拟页面（或称为虚拟内存页）的集合被分为三个不相交的子集：未分配的、缓存的和未缓存的。这些术语在虚拟内存管理中有特定的含义：

1. **未分配的（Unallocated）**:
   - 这些页面尚未被虚拟内存系统分配给任何进程。
   - 未分配的页面不包含任何数据，因此不占用物理内存或磁盘空间。
   - 当一个进程需要更多内存时，虚拟内存系统可能会分配这些未分配的页面。

2. **缓存的（Cached）**:
   - 缓存的页面是已经被分配给某个进程并且当前驻留在物理内存中的页面。
   - 这些页面包含数据，这些数据可能是程序代码、程序数据或其他形式的信息。
   - 当进程访问这些页面时，由于它们已经在物理内存中，访问速度非常快。

3. **未缓存的（Uncached）**:
   - 未缓存的页面也是已经被分配给某个进程的，但是当前并不驻留在物理内存中。
   - 这些页面可能被存储在辅助存储（如硬盘）上，这种情况通常称为“交换”（`Swapping`）或“分页”（`Paging`）。
   - 当进程尝试访问这些未缓存的页面时，必须先从辅助存储中将其加载到物理内存中，这个过程称为“页面错误”（`Page Fault`）处理，
   通常比直接访问物理内存慢得多。

在虚拟内存系统中，"缓存"和"未缓存"的概念主要与页面是否驻留在物理内存中有关。
缓存的页面可以快速访问，而未缓存的页面需要更多的时间来访问，因为它们需要从磁盘读取。
虚拟内存系统的目标之一是有效地管理这些不同类型的页面，以优化性能和内存利用率。
====================================================================================================

# DRAM 缓存的组织结构

为了有助于清晰理解存储层次结构中不同的缓存概念，我们将使用术语 *SRAM 缓存* 来表示位于 CPU 和主存之间的 Ll、L2 和 L3 高速缓存，并且用术语 DRAM 缓存来表示虚拟内存系统的缓存，它在主存中缓存虚拟页。

在存储层次结构中，DRAM 缓存的位置对它的组织结构有很大的影响。
回想一下，DRAM 比 SRAM 要慢大约 `10` 倍，而磁盘要比 DRAM 慢大约 `100000` 多倍。
因此，DRAM 缓存中的不命中比起 SRAM 缓存中的不命中要昂贵得多，这是因为 DRAM 缓存不命中要由磁盘来服务，而 SRAM 缓存不命中通常是由基于 DRAM 的主存来服务的。
而且，从磁盘的一个扇区读取第一个字节的时间开销比起读这个扇区中连续的字节要慢大约 1`00000` 倍。
归根到底，DRAM 缓存的组织结构完全是由巨大的不命中开销驱动的。

因为大的不命中处罚和访问第一个字节的开销，虚拟页往往很大，通常是 `4KB ~ 2MB`。由于大的不命中处罚，DRAM 缓存是*全相联*的，即任何虚拟页都可以放置在任何的物理页中。不命中时的替换策略也很重要，因为替换错了虚拟页的处罚也非常之高。因此，与硬件对 **SRAM** 缓存相比，操作系统对 **DRAM** 缓存使用了更复杂精密的替换算法。（这些替换算法超出了我们的讨论范围）。最后，因为对磁盘的访问时间很长，DRAM 缓存总是使用写回，而不是直写。
====================================================================================================
这段话讨论了虚拟内存页面、DRAM缓存、及其相关的缓存策略。我将逐点详细解释：

1. **虚拟页的大小**：虚拟页通常很大，大小在4KB到2MB之间。这是因为较大的页可以减少内存管理的复杂性和开销。较大的页减少了页表条目的数量，这样可以减少内存中页表的大小。

2. **不命中处罚**：不命中处罚是指当缓存尝试访问数据，而数据不在缓存中时，需要从更慢的存储（如DRAM或磁盘）中取得数据的开销。由于这种不命中的开销很大，所以需要设计有效的缓存策略来减少不命中的发生。

3. **DRAM缓存的全相联性**：全相联缓存是一种缓存映射技术，其中任何的数据块都可以放置在缓存的任何位置。这种设计允许高度的灵活性和命中率，但是实现起来较为复杂且成本较高。在这种背景下，DRAM缓存被设计为全相联，以减少不命中的可能性。

4. **不命中时的替换策略**：当发生缓存不命中时，需要选择一个现有的缓存条目来替换。由于错误选择替换项的处罚非常高（即可能导致更频繁的不命中），因此操作系统需要使用复杂精密的替换算法来决定哪个虚拟页被替换出缓存。

5. **与SRAM缓存的比较**：SRAM（静态随机存取存储器）通常用于硬件层面的缓存，如CPU的L1和L2缓存。与DRAM（动态随机存取存储器）相比，SRAM更快但更贵。操作系统管理的DRAM缓存相比硬件层面的SRAM缓存，使用了更复杂的替换算法。

6. **写回与直写策略**：在缓存策略中，写回（*write-back*）是指修改的数据首先缓存在DRAM中，只有在需要被替换时才写回到磁盘。而直写（*write-through*）策略是指数据同时写入DRAM和磁盘。由于磁盘的访问时间远长于DRAM，所以DRAM缓存通常使用写回策略，以减少对磁盘的访问次数，从而提高性能。
====================================================================================================

## 页表
同任何缓存一样，虚拟内存系统必须有某种方法来判定一个虚拟页是否缓存在 `DRAM` 中的某个地方。如果是，系统还必须确定这个虚拟页存放在哪个`物理页`中。
如果不命中，系统必须判断这个虚拟页存放在磁盘的哪个位置，在物理内存中选择一个`牺牲页`，并将虚拟页从磁盘复制到 DRAM 中，替换这个牺牲页。

这些功能是由软硬件联合提供的，包括*操作系统软件*、*MMU*（内存管理单元）中的*地址翻译硬件*和一个存放在物理内存中叫做页表（*page table*）的数据结构
页表将虚拟页映射到物理页。每次地址翻译硬件将一个虚拟地址转换为物理地址时，都会读取页表。操作系统负责维护页表的内容，以及在磁盘与 DRAM 之间来回传送页。

页表就是一个页表条目（`Page Table Entry`，PTE）的数组。
虚拟地址空间中的每个页在页表中一个固定偏移量处都有一个 PTE。
为了我们的目的，我们将假设每个 PTE 是由一个有效位（`valid bit`）和一个 `n` 位地址字段组成的。
有效位表明了该虚拟页当前是否被缓存在 DRAM 中。
 - 如果设置了有效位，那么地址字段就表示 DRAM 中相应的物理页的起始位置，这个物理页中缓存了该虚拟页。
 - 如果没有设置有效位，那么一个空地址表示这个虚拟页还未被分配。否则，这个地址就指向该虚拟页在磁盘上的起始位置。

====================================================================================================
页表是操作系统用于管理虚拟内存系统的一种数据结构。
在现代计算机系统中，虚拟内存允许程序认为它们拥有一致的、连续的内存空间，而实际上这些内存空间可能被分散存储在物理内存和磁盘上。页表就是用来跟踪虚拟地址和物理地址之间映射关系的关键结构。

### 页表的工作原理：

1. **虚拟内存分页**：在虚拟内存系统中，内存被划分为固定大小的块，称为“页”（通常大小为4KB）。相应地，物理内存也被划分为同样大小的块，称为“页帧”。

2. **页表**：页表是一个数据结构，通常存储在物理内存中。它包含了一系列的页表项（PTEs），每个PTE对应一个虚拟页，包含了该虚拟页对应的物理页帧的地址以及一些状态信息（如是否在物理内存中，是否被修改过等）。

3. **地址转换**：当程序访问一个虚拟地址时，操作系统或硬件（如MMU，内存管理单元）会使用页表来将这个虚拟地址转换为相应的物理地址。这个过程通常包括将虚拟地址分为“页号”和“页内偏移”两部分。页号用于查找页表中对应的PTE，以获取物理页框号；页内偏移在虚拟页和物理页框之间是相同的，用于定位具体的数据位置。

### 寻址映射过程举例：

假设我们有一个32位的虚拟地址空间，页的大小为4KB（即2^12字节），则每个虚拟地址可以分为20位的页号和12位的页内偏移。

例如，假设一个程序访问虚拟地址`0x00403F3C`：

1. **地址分解**：
   - 虚拟地址`0x00403F3C`可分为两部分：页号（高20位）`0x00403`和页内偏移（低12位）`0xF3C`。

2. **查找页表**：
   - 使用页号`0x00403`在页表中查找相应的PTE。

3. **获取物理页框**：
   - 假设页表项指示此虚拟页映射到物理页框`0x00102`。

4. **物理地址计算**：
   - 物理地址由物理页框号`0x00102`和原始的页内偏移`0xF3C`组合而成，结果为`0x00102F3C`。

在这个过程中，操作系统和硬件共同协作，确保每个程序的虚拟内存独立于其他程序，并且有效地映射到实际的物理内存上。
这样的机制使得程序可以高效地使用内存资源，同时也保护了各个程序间的内存空间不被其他程序非法访问。
====================================================================================================


# 页命中

考虑一下当 CPU 想要读包含在 `VP2` 中的虚拟内存的一个字时会发生什么（图 9-5），VP 2 被缓存在 DRAM 中。
使用我们将在 9.6 节中详细描述的一种技术，`地址翻译硬件`将虚拟地址作为一个索引来定位 PTE 2，并从内存中读取它。
因为设置了有效位，那么地址翻译硬件就知道 VP 2 是缓存在内存中的了。所以它使用 PTE 中的物理内存地址（该地址指向 `PP 1` 中缓存页的起始位置），构造出这个字的物理地址。

当然，我将使用 ASCII 字符来创建一个简单的图表，展示虚拟地址到物理地址的映射过程。请注意，由于 ASCII 图形的局限性，这个图表将非常基础。

```
+---------------+      +------------------+      +------------------+
| Virtual       |      | Page Table       |      | Physical Memory  |
| Address       |      | (in Memory)      |      |                  |
|               |      |                  |      |                  |
|  +---------+  |      |  +----------+    |      |  +----------+    |
|  | Page    |  |      |  | PTE for  |    |      |  | Physical |    |
|  | Number  |----------->| Page     |------------> | Page     |    |
|  |         |  |      |  | Number   |    |      |  | Frame    |    |
|  +---------+  |      |  +----------+    |      |  +----------+    |
|  | Offset  |  |      |                  |      |  | Offset   |    |
|  +---------+  |      |  ...             |      |  +----------+    |
|               |      |                  |      |                  |
+---------------+      +------------------+      +------------------+
```

在这个图表中：

- **Virtual Address**：虚拟地址由“页号”和“页内偏移”组成。
- **Page Table**：页表包含多个页表项（PTEs），每个PTE对应一个虚拟页。图中显示了虚拟页号对应的PTE。
- **Physical Memory**：物理内存由多个物理页框组成。图中显示了由PTE指定的物理页框。

虚拟地址的页号部分用来在页表中查找对应的PTE，PTE指明了物理页框的位置。虚拟地址的页内偏移在虚拟页和物理页框中是一致的，直接用于定位具体数据。


# 缺页
在虚拟内存的习惯说法中，DRAM 缓存不命中称为缺页（`page fault`）。
图 9-6 展示了在缺页之前我们的示例页表的状态。CPU 引用了 `VP 3` 中的一个字，VP 3 并未缓存在 DRAM 中。
地址翻译硬件从内存中读取 PTE 3，从有效位推断出 VP 3 未被缓存，并且触发一个`缺页异常`。
缺页异常调用内核中的缺页异常处理程序，该程序会选择一个牺牲页，在此例中就是存放在 `PP 3` 中的 `VP 4`。
如果 VP 4 已经被修改了，那么内核就会将它复制回磁盘。无论哪种情况，内核都会修改 VP 4 的页表条目，反映出 VP 4 不再缓存在主存中这一事实。

缺页处理程序选择 VP 4 作为牺牲页，并从磁盘上用 VP 3 的副本取代它。
在缺页处理程序重新启动导致缺页的指令之后，该指令将从内存中正常地读取字，而不会再产生异常

虚拟内存是在 20 世纪 60 年代早期发明的，远在 CPU - 内存之间差距的加大引发产生 SRAM 缓存之前。
因此，虚拟内存系统使用了和 SRAM 缓存不同的术语，即使它们的许多概念是相似的。在虚拟内存的习惯说法中，块被称为页。
在磁盘和内存之间传送页的活动叫做交换（`swapping`）或者页面调度（`paging`）。页从磁盘换入（或者页面调入）DRAM 和从 DRAM 换出（或者页面调出）磁盘。一直等待，直到最后时刻，也就是当有不命中发生时，才换入页面的这种策略称为按需页面调度（`demand paging`）。也可以采用其他的方法，例如尝试着预测不命中，在页面实际被引用之前就换入页面。然而，所有现代系统都使用的是按需页面调度的方式。

====================================================================================================
当发生缺页中断（page fault）时，意味着一个程序试图访问的虚拟内存页当前不在物理内存中。
这可能是由于多种原因造成的，如页面初次被访问、页面被换出到磁盘（换出是操作系统为了管理有限的物理内存而进行的操作），或者访问了非法内存地址。以下是在缺页中断后发生的一般过程：

1. **中断触发**：当程序访问一个不在物理内存中的虚拟页时，硬件（通常是内存管理单元MMU）会触发一个缺页中断。

2. **操作系统介入**：缺页中断将控制权转交给操作系统。操作系统的缺页中断处理程序首先确定缺页的原因。

3. **检查有效性**：操作系统检查请求的虚拟地址是否有效和合法。如果地址非法（例如，指向未分配的内存区域），操作系统可能会终止导致中断的程序。

4. **查找交换区**：如果地址合法，操作系统将检查该页面是否已被换出到硬盘上的交换空间（`swap space`）。

5. **选择牺牲页**：如果物理内存已满，操作系统将选择一个物理内存中的页面作为牺牲页，以腾出空间。这通常涉及到页面置换算法，如最近最少使用（`LRU`）算法。

6. **换出牺牲页**：如果选定的牺牲页自上次被读入内存以来已被修改过，操作系统将其写回到硬盘上的交换区。如果该页未被修改，则直接丢弃。

7. **换入请求页**：操作系统从硬盘的交换区中将缺失的页读入刚刚腾出的物理内存空间。

8. **更新页表**：操作系统更新页表，将新换入的页映射到相应的物理内存地址，并重置页面访问权限。

9. **恢复执行**：最后，操作系统恢复中断前被暂停的程序执行，重新开始执行导致缺页中断的指令。由于现在所需的页已在物理内存中，程序可以继续运行而不会再次触发缺页中断。

这个过程是现代操作系统虚拟内存管理的关键组成部分，它允许系统更有效地使用有限的物理内存资源，同时为应用程序提供了更大的看似连续的内存空间。
====================================================================================================

# 分配页面
图 9-8 展示了当操作系统分配一个新的虚拟内存页时对我们示例页表的影响，例如，调用 malloc 的结果。
在这个示例中，VP5 的分配过程是在磁盘上创建空间并更新 `PTE 5`，使它指向磁盘上这个新创建的页面。



# 又是局部性救了我们

当我们中的许多人都了解了虚拟内存的概念之后，我们的第一印象通常是它的效率应该是非常低。因为不命中处罚很大，我们担心页面调度会破坏程序性能。*
实际上，虚拟内存工作得相当好，这主要归功于我们的老朋友局部性（**locality**）。

尽管在整个运行过程中程序引用的不同页面的总数可能超出物理内存总的大小，但是局部性原则保证了在任意时刻，程序将趋向于在一个较小的活动页面（`active page`）集合上工作，这个集合叫做工作集（`working set`）或者常驻集合（`resident set`）。
在初始开销，也就是将工作集页面调度到内存中之后，接下来对这个工作集的引用将导致命中，而不会产生额外的磁盘流量。

只要我们的程序有好的时间局部性，虚拟内存系统就能工作得相当好。
但是，当然不是所有的程序都能展现良好的时间局部性。如果工作集的大小超出了物理内存的大小，那么程序将产生一种不幸的状态，叫做抖动（`thrashing`），这时页面将不断地换进换出。虽然虚拟内存通常是有效的，但是如果一个程序性能慢得像爬一样，那么聪明的程序员会考虑是不是发生了抖动。

====================================================================================================
局部性原理是计算机科学中一个非常重要的概念，尤其在计算机体系结构和操作系统的设计中起着关键作用。
局部性原理基于这样一个观察：计算机程序在执行过程中倾向于在时间上和空间上集中访问相对较小的一部分数据和指令。
局部性原理主要分为两种类型：时间局部性（Temporal Locality）和空间局部性（Spatial Locality）。

1. **时间局部性**：
   时间局部性是指程序中的某些项（数据或指令）如果在某一时刻被访问，那么它们在不久的将来可能会被再次访问。例如，循环中的指令和循环变量就展示了很强的时间局部性。

2. **空间局部性**：
   空间局部性是指如果程序在某一时刻访问了某个数据项，那么它在不久的将来很可能访问这个数据项附近的数据。例如，顺序执行的指令和数组中紧挨着的元素就是空间局部性的体现。

### 局部性原理在计算机中的应用：
1. **缓存设计**：
   局部性原理是缓存（Cache）设计的基础。由于程序倾向于重复访问相同的数据或指令（时间局部性），以及倾向于访问紧邻的数据项（空间局部性），缓存可以临时存储这些数据，以加快访问速度。当CPU需要访问数据时，它首先检查数据是否已在缓存中，如果是，则无需访问较慢的主存储器。

2. **预取策略**：
   依据局部性原理，许多系统采用预取（Prefetching）策略，即提前从内存中加载可能很快会被访问的数据到缓存中。这是基于空间局部性原理，预测哪些数据很可能在接下来被需要。

3. **分支预测**：
   在现代处理器中，分支预测技术用来猜测程序执行路径，这也部分依赖于时间局部性原理。如果一个特定的分支在过去被多次执行，那么预测器可能会假设这个分支在未来也会被执行。

4. **虚拟内存管理**：
   操作系统使用局部性原理来有效管理虚拟内存。例如，页面置换算法（如最近最少使用LRU算法）就是基于时间局部性原理，假设最近最少被访问的页面在未来也不太可能被访问。

5. **编译器优化**：
   编译器在生成代码时也利用局部性原理来优化程序性能。例如，它可能会重新安排循环以提高数据的空间和时间局部性，或者在生成机器代码时，将频繁使用的变量放在寄存器中。

6. **并行计算和分布式系统**：
   在并行计算和分布式系统中，局部性原理被用来最小化节点之间的通信，优化数据存储和计算任务的分配。

局部性原理在计算机科学的许多领域都有应用，其对于理解和设计更高效的计算机系统架构、操作系统策略、编译器优化等方面至关重要。
====================================================================================================


> 旁注 - 统计缺页次数
> 你可以利用 Linux 的 getrusage 函数监测缺页的数量（以及许多其他的信息）。

在 Linux 系统中，`getrusage` 函数是一个非常有用的工具，用于获取有关当前进程或进程组的资源使用情况信息，包括缺页中断的次数。
这个函数定义在 `<sys/resource.h>` 头文件中，它可以报告多种类型的资源使用情况，包括用户CPU时间、系统CPU时间、页面交换次数等。

以下是如何使用 `getrusage` 函数来监测缺页数量的基本步骤：

1. **包含必要的头文件**：
   首先，你需要在程序中包含 `<sys/resource.h>` 头文件。
   ```c
   #include <sys/resource.h>
   ```

2. **调用 getrusage 函数**：
   使用 `getrusage` 函数获取资源使用情况。这个函数需要两个参数：请求的资源类型和一个指向 `struct rusage` 的指针，该结构将被填充资源使用信息。
   ```c
   struct rusage usage;
   getrusage(RUSAGE_SELF, &usage);
   ```

   在这里，`RUSAGE_SELF` 指的是当前进程。

3. **检查缺页数**：
   `struct rusage` 结构包含了多个字段，其中两个字段 `ru_minflt` 和 `ru_majflt` 分别代表无需加载页面的缺页（minor faults）和需要加载页面的缺页（major faults）。
   ```c
   long minor_faults = usage.ru_minflt;
   long major_faults = usage.ru_majflt;
   ```

4. **打印或处理缺页数据**：
   然后，你可以根据需要打印、记录或以其他方式处理这些缺页数据。

5. **示例代码**：
   下面是一个简单的示例程序，演示如何使用 `getrusage` 来监测和打印缺页数量：
   ```c
   #include <stdio.h>
   #include <sys/resource.h>

   int main() {
       struct rusage usage;
       getrusage(RUSAGE_SELF, &usage);

       printf("Minor faults: %ld\n", usage.ru_minflt);
       printf("Major faults: %ld\n", usage.ru_majflt);

       return 0;
   }
   ```

在这个例子中，程序将会输出当前进程的缺页中断次数。请注意，这个信息是从程序开始执行到调用 `getrusage` 时刻的累积数据。
如果你希望监视特定代码段的缺页情况，需要在该段代码执行前后分别调用 `getrusage`，并计算两次调用结果之间的差异。


