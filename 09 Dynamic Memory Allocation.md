# Dynamic Memory Allocation
# 动态内存分配

虽然可以使用低级的 `mmap` 和 `munmap` 函数来创建和删除虚拟内存的区域，但是 C 程序员还是会觉得当运行时需要额外虚拟内存时，用动态内存分配器（`dynamic memory allocator`）更方便，也有更好的可移植性。

动态内存分配器维护着一个进程的虚拟内存区域，称为*堆*（`heap`）（见图 9-33）。
系统之间细节不同，但是不失通用性，假设堆是一个请求二进制零的区域，它紧接在未初始化的数据区域后开始，并向上生长（向更高的地址）。对于每个进程，内核维护着一个变量 `brk`（读做 “break”），它指向堆的顶部。

====================================================================================================
动态内存分配器是操作系统或运行时环境提供的一种机制，用于在程序运行期间动态地分配、管理和释放内存。这种分配器主要操作的内存区域是称为“堆”（heap）的部分。在 C 和 C++ 程序中，动态内存分配通常通过 `malloc`, `calloc`, `realloc`, 和 `free` 等函数实现。在其他高级语言中，也有类似的机制，比如 Java 中的 `new` 和 Python 中的内存分配。

### 动态内存分配器的工作原理：
1. **堆（Heap）**：
   - 堆是进程虚拟内存空间的一部分，用于动态内存分配。
   - 它通常位于未初始化数据区域（BSS段）和栈空间之间。
   - 堆的大小不是在程序编译时确定的，而是在运行时根据需要动态扩展和缩减的。
2. **堆的生长**：
   - 堆向上生长，即向更高的内存地址扩展。随着动态分配的内存需求增加，堆的大小也会增加。
3. **`brk` 和 `sbrk`**：
   - 内核维护着一个名为 `brk` 的指针，它指向堆的当前顶部。
   - `sbrk()` 函数是一个系统调用，用于增加或减少 `brk` 指针的值，从而改变堆的大小。在某些系统中，`brk` 也可能是一个系统调用。
4. **内存分配请求**：
   - 当程序调用如 `malloc()` 这样的函数请求内存时，动态内存分配器会在堆上查找足够大的、未被使用的内存块。
   - 如果堆上没有足够的空间，分配器会请求操作系统增加堆的大小（例如通过 `sbrk()` 或类似机制）。
5. **内存释放**：
   - 当程序通过 `free()` 或类似函数释放内存时，该内存块标记为未使用，可以被后续的分配请求重用。
   - 在某些情况下，如果堆变得太大，动态内存分配器可能会缩小堆的大小，释放内存回操作系统。
### 注意事项：

- 动态内存分配要求程序员负责正确地分配和释放内存。不当的使用可能导致内存泄露、悬挂指针或内存碎片等问题。
- 一些高级语言（如 Java、Python）提供了垃圾收集器来自动管理内存分配和回收，减少了手动管理内存的需要。

动态内存分配器是程序设计中处理内存的重要组件，它在提供灵活的内存管理的同时，也要求程序员对内存使用有深入理解。


动态内存分配器如何管理堆内存。
在这种管理模式下，堆被视为一系列内存块（blocks）的集合，每个块代表一段连续的虚拟内存区域（chunks）。这些块可以是已分配的，也可以是空闲的。以下是对这个过程的进一步解释：
### 堆的内存块管理

1. **块的状态**：
   - **已分配块**：这些块被应用程序使用，用于存储数据。当程序调用如 `malloc()` 或 `new` 等分配函数时，分配器会提供一个已分配块的地址。
   - **空闲块**：这些块当前没有被使用，可以用于后续的内存分配请求。它们保持空闲，直到被分配器再次分配给应用程序。

2. **块的分配和释放**：
   - 当应用程序请求内存时，分配器会在空闲块中查找合适的块来满足这个请求。如果找到合适的块，它会被标记为已分配，并提供给应用程序。
   - 当应用程序不再需要这些内存时，它应该显式地释放内存（如通过 `free()` 或 `delete`）。释放后，这些块再次变成空闲块。

3. **内存块的合并和分割**：
   - 为了有效地管理内存，分配器可能会根据需要对空闲块进行合并，以创建更大的空闲块。
   - 相反地，如果应用程序请求的内存小于一个空闲块的大小，分配器可能会将这个空闲块分割成更小的块。

4. **维护内存块信息**：
   - 通常，每个块都会有一些管理信息，比如大小、状态（已分配或空闲）、以及可能的链接到其他块的指针。
   这些信息帮助分配器跟踪堆上的内存使用情况。

### 内存分配器的挑战
- **内存碎片**：频繁的分配和释放可能导致内存碎片，其中堆中的可用内存被小的不连续空间分割开。
- **性能考虑**：分配器需要在内存利用率和分配效率之间找到平衡。快速响应内存请求与最大化内存使用效率是分配器设计的两个关键目标。
- **安全性和健壮性**：分配器还需要处理错误情况，例如请求超过可用内存的情况，并确保其操作不会导致内存泄露或其他安全问题。

动态内存分配器的设计和实现是计算机科学中的一个复杂领域，涉及多种算法和策略，以在性能、效率和可靠性之间取得平衡。
====================================================================================================

分配器将堆视为一组不同大小的块（`block`）的集合来维护。每个块就是一个连续的虚拟内存片（`chunk`），要么是已分配的，要么是空闲的。

已分配的块显式地保留为供应用程序使用。空闲块可用来分配。空闲块保持空闲，直到它显式地被应用所分配。
一个已分配的块保持已分配状态，直到它被释放，这种释放要么是应用程序显式执行的，要么是内存分配器自身隐式执行的。

分配器有两种基本风格。两种风格都要求应用显式地分配块。它们的不同之处在于由哪个实体来负责释放已分配的块。

- `显式分配器`（`explicit allocator`），要求应用显式地释放任何已分配的块。
   例如，C 标准库提供一种叫做 malloc 程序包的显式分配器。C 程序通过调用 `malloc` 函数来. 分配一个块，并通过调用 `free` 函数来释放一个块。
   C++ 中的 new 和 delete 操作符与 C 中的 malloc 和 free 相当。

- `隐式分配器（implicit allocator）`，另一方面，要求分配器检测一个已分配块何时不再被程序所使用，那么就释放这个块。
   隐式分配器也叫做垃圾收集器（`garbage collector`），而自动释放未使用的已分配的块的过程叫做垃圾收集（`garbage collection`）。例如，诸如 Lisp、ML 以及 Java 之类的高级语言就依赖垃圾收集来释放已分配的块。

本节剩下的部分讨论的是显式分配器的设计和实现。
我们将在 9.10 节中讨论隐式分配器。为了更具体，我们的讨论集中于管理堆内存的分配器。然而，应该明白`内存分配`是一个普遍的概念，可以出现在各种上下文中。例如，`图形处理密集`的应用程序就经常使用标准分配器来要求获得一大块虚拟内存，然后使用与应用相关的分配器来管理内存，在该块中创建和销毁图形的节点。

====================================================================================================
# `malloc` 和 `free` 函数

C 标准库提供了一个称为 malloc 程序包的显式分配器。程序通过调用 malloc 函数来从堆中分配块。
~~~c
#include <stdlib.h>

void *malloc(size_t size);

// 返回：若成功则为已分配块的指针，若出错则为 NULL。
~~~

`malloc` 函数返回一个指针，指向大小为至少 size 字节的内存块，这个块会为可能包含在这个块内的任何数据对象类型做对齐。

实际中，对齐依赖于编译代码在 32 位模式（gcc -m32）还是 64 位模式（默认的）中运行。
在 32 位模式中，malloc 返回的块的地址总是 8 的倍数。在 64 位模式中，该地址总是 16 的倍数。

`malloc()` 是 C 语言标准库中提供的一个函数，用于动态地从堆（heap）中分配内存。
它是显式分配器的一部分，允许程序在运行时请求特定大小的内存块。以下是对 `malloc()` 函数的详细介绍：

### 函数原型

```c
#include <stdlib.h>

void *malloc(size_t size);
```

- **参数**：
  - `size`：要分配的内存块的大小，以字节为单位。

### 返回值

- **成功时**：返回一个指向新分配的内存块的指针。
- **失败时**：返回 `NULL`。失败的原因通常是因为堆空间不足以满足分配请求。

### 工作原理

- 当调用 `malloc(size)` 时，分配器会在堆上查找足够大的、未被使用的内存块。
- 如果找到合适的块，分配器会将其标记为已分配，并返回一个指向这块内存的指针。
- 分配的内存块不会被初始化，其内容是未定义的。这意味着新分配的内存可能包含任意数据。

### 使用示例

```c
int *array = malloc(10 * sizeof(int));
if (array == NULL) {
    // 处理内存分配失败的情况
}

// 使用 array...

free(array); // 完成后释放内存
```

### 注意事项

- **内存泄漏**：每次使用 `malloc()` 分配内存后，应该相应地调用 `free()` 来释放内存。否则，会导致内存泄漏。
- **错误检查**：因为 `malloc()` 可能因为内存不足而失败，所以总是应该检查其返回值是否为 `NULL`。
- **初始化**：`malloc()` 分配的内存是未初始化的。如果需要初始化为零，可以使用 `calloc()` 函数。
- **重新分配**：可以使用 `realloc()` 函数来更改已分配内存块的大小。

`malloc()` 是 C 程序中管理动态内存的基础，它为灵活的内存使用提供了必要的机制。
正确和有效地使用 `malloc()` 对于防止内存相关错误和提高程序效率至关重要。

====================================================================================================
内存对齐是计算机系统中用于提高内存访问效率的一种技术。它涉及按照特定的边界地址分配内存，以确保数据的地址符合特定的对齐规则。
在现代计算机架构中，内存对齐对于优化性能是非常重要的。以下是对内存对齐的详细解释：

### 为什么需要内存对齐
1. **硬件效率**：
   - 许多计算机系统的硬件设计要求数据在内存中按照一定的边界对齐。
   对齐的数据可以一次性、高效地从内存传输到CPU，否则可能需要多次内存访问才能读取或写入非对齐的数据。
2. **性能提升**：
   - 对齐的内存访问通常比非对齐的访问更快。非对齐的内存访问可能导致附加的处理器周期和更多的内存访问，从而降低程序的运行效率。
3. **硬件要求**：
   - 某些硬件平台只支持对齐的内存访问；在这些平台上，非对齐的访问可能导致硬件异常或程序崩溃。

### 对齐的具体规则
- 对齐的具体规则取决于处理器架构和操作系统。在32位系统中，`malloc()` 通常返回8字节对齐的内存地址；而在64位系统中，通常返回16字节对齐的地址。
- 这意味着分配的内存地址可以被8或16整除。例如，在64位系统中，如果 `malloc()` 返回地址 `0x10010`，则该地址能够被16整除。

### 内存对齐在编程中的影响
- 在编写程序时，特别是在处理指针和内存操作时，考虑内存对齐是很重要的。
- 大多数高级编程语言和它们的运行时环境会自动处理内存对齐的问题。但在低级编程（如C或C++中直接处理内存时），程序员可能需要更加注意内存对齐的问题。
- 对于结构体和类的成员变量，编译器通常会自动添加填充（`padding`）以确保每个成员都按照其自然对齐方式放置。

内存对齐是计算机体系结构中的一个基本概念，它旨在确保数据访问的最优化，特别是在处理大量数据或要求高性能的应用中。
在大多数情况下，编译器和运行时环境会处理对齐的问题，但了解这一概念仍然对于理解和优化程序性能非常重要。

====================================================================================================

> 旁注 - 一个字有多大
> 回想一下在第 3 章中我们对机器代码的讨论，Intel 将 4 字节对象称为双字。
> 然而，在本节中，我们会假设字是 4 字节的对象，而双字是 8 字节的对象，这和传统术语是一致的。

如果 `malloc` 遇到问题（例如，程序要求的内存块比可用的虚拟内存还要大），那么它就返回 `NULL`，并设置 `errno`。
`malloc` 不初始化它返回的内存。那些想要已初始化的动态内存的应用程序可以使用 `calloc`，calloc 是一个基于 malloc 的瘦包装函数，它将分配的内存初始化为零。想要改变一个以前已分配块的大小，可以使用 `realloc` 函数。
 - `calloc()` 
 - `realloc()`

动态内存分配器，例如 malloc，可以通过使用 mmap 和 munmap 函数，显式地分配和释放堆内存，或者还可以使用 `sbrk` 函数：
~~~c
#include <unistd.h>

void *sbrk(intptr_t incr);

// 返回：若成功则为旧的 brk 指针，若出错则为 -1。
~~~

`sbrk()` 是 Unix 和类 Unix 系统中的一个系统调用，用于调整进程堆区域的大小。
堆是进程的一个虚拟内存区域，用于动态内存分配。`sbrk()` 通过修改内核中的 `brk` 指针来扩展或收缩堆。下面是对 `sbrk()` 函数的详细解释：

### 函数原型

```c
#include <unistd.h>

void *sbrk(intptr_t incr);
```

- **参数**：
  - `incr`：要改变堆大小的字节数。如果 `incr` 是正数，堆将扩展；如果是负数，堆将收缩。

### 返回值

- **成功时**：返回调用之前的 `brk` 指针值。也就是说，如果 `incr` 是正数，则返回值是扩展前的堆顶地址；如果 `incr` 是负数，则返回值是收缩前的堆顶地址。
- **失败时**：返回 `(void *) -1`，并设置 `errno` 为 `ENOMEM`。失败通常是由于没有足够的内存空间来满足扩展请求。

### 使用方式

- **获取当前堆顶**：调用 `sbrk(0)` 可以获取当前的 `brk` 值，即当前堆的顶部地址。
- **扩展堆**：使用正的 `incr` 值调用 `sbrk(incr)` 可以扩展堆。
- **收缩堆**：使用负的 `incr` 值调用 `sbrk(incr)` 可以收缩堆。

### 注意事项

- `sbrk()` 相对于现代分配函数（如 `malloc()` 和 `free()`）来说是较低级的接口。
在多线程程序中直接使用 `sbrk()` 可能不安全，因为它可能与标准库的内存分配器发生冲突。

- 现代系统中通常推荐使用 `malloc()`、`calloc()`、`realloc()` 和 `free()` 这样的高级内存分配函数，它们在内部可能使用 `sbrk()` 或其他机制来管理内存，同时提供了更安全和更方便的接口。

- 直接使用 `sbrk()` 进行内存管理要求程序员非常清楚地了解内存分配和释放的细节，以避免内存泄漏、碎片化等问题。

尽管 `sbrk()` 在现代编程中不常直接使用，了解它的工作原理仍对理解操作系统如何管理内存是有帮助的。

sbrk 函数通过将内核的 `brk` 指针增加 `incr` 来扩展和收缩堆。
 - 如果成功，它就返回 brk 的旧值，否则，它就返回 -1，并将 errno 设置为 ENOMEM。
 - 如果 incr 为零，那么 sbrk 就返回 brk 的当前值。用一个为负的 incr 来调用 sbrk 是合法的，而且很巧妙，因为返回值（brk 的旧值）指向距新堆顶向上 *abs(incr)* 字节处。

程序是通过调用 free 函数来释放已分配的堆块。

~~~c
#include <stdlib.h>

void free(void *ptr);

// 返回：无。
~~~
ptr 参数必须指向一个从 `malloc`、`calloc` 或者 `realloc` 获得的已分配块的起始位置。
如果不是，那么 free 的行为就是未定义的。
更糟的是，既然它什么都不返回，free 就不会告诉应用出现了错误。就像我们将在 9.11 节里看到的，这会产生一些令人迷惑的运行时错误。

图 9-34 展示了一个 *malloc* 和 *free* 的实现是如何管理一个 C 程序的 16 字的（非常）小的堆的。每个方框代表了一个 4 字节的字。
粗线标出的矩形对应于已分配块（有阴影的）和空闲块（无阴影的）。
初始时，堆是由一个大小为 16 个字的、双字对齐的、空闲块组成的。（*本节中，我们假设分配器返回的块是 8 字节双字边界对齐的*）

~~~shell
1. 程序请求一个 4 字的块
malloc 的响应是：从空闲块的前部切出一个 4 字的块，并返回一个指向这个块的第一字的指针。
[*][*][*][*][ ][ ][ ][ ][ ][ ][ ][ ][ ][ ][ ][ ][ ][ ][ ][ ][ ][ ]
⬆
p1
p1 = malloc(4 * sizeof(int)) 

2. 程序请求一个 5 字的块
malloc 的响应是：从空闲块的前部分配一个 6 字的块。
在本例中，malloc 在块里填充了一个额外的字，是为了保持空闲块是双字边界对齐的。
[*][*][*][*][*][*][*][*][*][$][ ][ ][ ][ ][ ][ ][ ][ ][ ][ ][ ][ ]
⬆           ⬆
p1          p2
p2 = malloc(5 * sizeof(int))

3. 程序请求一个 6 字的块
malloc 就从空闲块的前部切出一个 6 字的块。
[*][*][*][*][*][*][*][*][*][$][*][*][*][*][*][*][ ][ ][ ][ ][ ][ ]
⬆           ⬆                 ⬆
p1          p2                p3
p3 = malloc(6 * sizeof(int))

4. 程序释放在p2中分配的那个 6 字的块。
注意，在调用 free 返回之后，指针 p2 仍然指向被释放了的块。
应用有责任在它被一个新的 malloc 调用重新初始化之前，不再使用 p2。
[*][*][*][*][ ][ ][ ][ ][ ][ ][*][*][*][*][*][*][ ][ ][ ][ ][ ][ ]
⬆           ⬆                 ⬆
p1          p2                p3
free(p2)

5. 程序请求一个 2 字的块。
在这种情况中，malloc 分配在前一步中被释放了的块的一部分，并返回一个指向这个新块的指针。
[*][*][*][*][*][*][ ][ ][ ][ ][*][*][*][*][*][*][ ][ ][ ][ ][ ][ ]
⬆           ⬆                 ⬆
p1          p2,p4             p3
~~~
图 9-34 用 malloc 和 free 分配和释放块。
每个方框对应于一个字。每个粗线标出的矩形对应于一个块。
阴影部分是已分配的块[*]。已分配的块的填充区域是深阴影[$]的。无阴影部分是空闲块[ ]。堆地址是从左往右增加的

# 为什么要使用动态内存分配？
====================================================================================================
动态内存分配在许多编程场景中非常重要，主要原因是它提供了灵活性和高效性。
以下是使用动态内存分配的几个关键原因：

1. **灵活的内存管理**：
   - 动态内存分配允许程序在运行时根据需要分配内存。
   这意味着程序可以根据当前数据的大小和数量来分配恰当的内存量，而不是在编译时预先分配固定大小的内存。
   - 这对于处理不确定大小的数据结构（如链表、树结构、图等）或读取不同大小文件的程序尤其重要。

2. **节省内存资源**：
   - 动态分配内存有助于节省系统资源。通过只分配所需的内存，程序可以更高效地使用有限的内存资源，从而降低内存浪费。

3. **处理大量数据**：
   - 对于需要处理大量数据的程序，如图像处理或文件操作，静态内存分配可能无法满足需求，因为它受限于程序的数据段或堆栈大小。动态内存分配允许分配足够大的内存块来处理这些大数据集。

4. **可扩展性和模块化**：
   - 动态内存分配支持更高的可扩展性和模块化设计。库和模块可以根据实际使用情况分配和释放内存，而不需要知道其他模块的内存使用情况。

5. **生命周期控制**：
   - 使用动态内存分配，程序员可以精确控制数据的生命周期。可以在需要时创建数据，在不再需要时销毁，这对于构建复杂的数据结构和管理资源非常重要。

6. **程序响应性**：
   - 对于需要根据用户输入或实时数据变化而调整内存使用的程序，动态内存分配提供了必要的灵活性，从而提高程序的响应性和效率。

### 注意事项
虽然动态内存分配提供了以上优点，但它也带来了一些挑战，如内存泄漏、内存碎片化和分配失败的处理。
因此，正确和高效地使用动态内存分配是程序设计中的一个重要方面。在现代编程中，许多高级语言提供了垃圾收集机制来自动管理内存，减轻了程序员直接管理内存的负担。
====================================================================================================

程序使用动态内存分配的最重要的原因是经常直到程序实际运行时，才知道某些数据结构的大小。
例如，假设要求我们编写一个 `C` 程序，它读一个 `n` 个 ASCII 码整数的链表，每一行一个整数，从 `stdin` 到一个 `C` 数组。
输入是由整数 `n` 和接下来要读和存储到数组中的 `n` 个整数组成的。
最简单的方法就是静态地定义这个数组，它的最大数组大小是硬编码的：

~~~c
#include "csapp.h"
#define MAXN 15213

int array[MAXN];

int main()
{
    int i, n;
    
    scanf("%d", &n);
    if (n > MAXN)
        app_error("Input file too big");
    for (i = 0; i < n; i++)
        scanf("%d", &array[i]);
    exit(0);
}
~~~

像这样用硬编码的大小来分配数组通常不是一种好想法。`MAXN` 的值是任意的，与机器上可用的虚拟内存的实际数量没有关系。
而且，如果这个程序的使用者想读取一个比 MAXN 大的文件，唯一的办法就是用一个更大的 MAXN 值来重新编译这个程序。
虽然对于这个简单的示例来说这不成问题，但是硬编码数组界限的出现对于拥有百万行代码和大量使用者的大型软件产品而言，会变成一场维护的噩梦。

一种更好的方法是在运行时，在已知了 n 的值之后，动态地分配这个数组。
使用这种方法，数组大小的最大值就只由可用的虚拟内存数量来限制了。

~~~c
#include "csapp.h"

int main()
{
    int *array, i, n;
    
    scanf("%d", &n);
    array = (int *)Malloc(n * sizeof(int));
    for (i = 0; i < n; i++)
        scanf("%d", &array[i]);
    free(array);
    exit(0);
}
~~~

动态内存分配是一种有用而重要的编程技术。
然而，为了正确而高效地使用分配器，程序员需要对它们是如何工作的有所了解。
我们将在 9.11 节中讨论因为不正确地使用分配器所导致的一些可怕的错误。


# 分配器的要求和目标
显式分配器必须在一些相当严格的约束条件下工作：

 - **处理任意请求序列** 一个应用可以有任意的分配请求和释放请求序列，只要满足约束条件：每个释放请求必须对应于一个当前已分配块，这个块是由一个以前的分配请求获得的。因此，分配器不可以假设分配和释放请求的顺序。例如，分配器不能假设所有的分配请求都有相匹配的释放请求，或者有相匹配的分配和空闲请求是嵌套的。
 - **立即响应请求** 分配器必须立即响应分配请求。因此，不允许分配器为了提高性能重新排列或者缓冲请求。
 - **只使用堆** 为了使分配器是可扩展的，分配器使用的任何非标量数据结构都必须保存在堆里。
 - **对齐块（对齐要求）** 分配器必须对齐块，使得它们可以保存任何类型的数据对象。
 - **不修改已分配的块** 分配器只能操作或者改变空闲块。特别是，一旦块被分配了，就不允许修改或者移动它了。因此，诸如压缩已分配块这样的技术是不允许使用的。

在这些限制条件下，分配器的编写者试图实现吞吐率最大化和内存使用率最大化，而这两个性能目标通常是相互冲突的。
====================================================================================================

您提到的约束条件是在设计和实现动态内存分配器时需要考虑的关键要求。
这些要求确保了分配器能够适应各种不同的内存分配和释放模式，同时保持高效和安全。
让我们逐一详细解释这些约束条件：

### 1. 处理任意请求序列

- **意义**：分配器必须能够处理任何合法的分配和释放请求序列。每个释放请求必须对应一个当前已分配的块，且该块是由之前的分配请求获得的。
- **挑战**：这意味着分配器不能对分配和释放请求的顺序做出假设。例如，它不能假设所有分配请求最终都会有对应的释放请求，也不能假设分配和释放是嵌套或顺序发生的。

### 2. 立即响应请求

- **意义**：分配器必须在收到分配请求时立即进行处理，而不能延迟处理或缓冲请求以待后续操作。
- **挑战**：这限制了分配器在提高效率方面的操作空间。例如，分配器不能将多个请求一起处理以优化内存使用或减少碎片。

### 3. 只使用堆

- **意义**：分配器使用的所有数据结构（如空闲块列表、树等）都必须存储在堆内存中。
- **挑战**：这要求分配器自己管理其使用的数据结构，同时确保这些结构不会干扰正常的内存分配和释放操作。

### 4. 对齐块（对齐要求）

- **意义**：分配器分配的内存块必须适当对齐，以便可以用来存储任何类型的数据对象。
- **挑战**：对齐通常涉及到在内存块的开始处留出一定的空间，以确保数据地址符合硬件要求。这可能导致内存的轻微浪费。

### 5. 不修改已分配的块

- **意义**：一旦块被分配给应用程序，分配器就不能再修改或移动这个块。这意味着不能使用如内存压缩等技术。
- **挑战**：这限制了分配器在管理内存碎片方面的能力。

### 性能目标冲突

在这些限制下，分配器的主要性能目标是最大化吞吐率（分配和释放操作的速度）和内存利用率（减少浪费的内存量）。
然而，这两个目标通常是相互冲突的：

- 提高吞吐率可能需要简化分配和释放操作，但这可能导致内存利用率降低（例如，更多的内存碎片）。
- 提高内存利用率可能需要更复杂的内存管理策略，但这可能降低分配和释放操作的速度。

因此，设计一个高效的动态内存分配器需要在这两个目标之间寻找平衡点。
====================================================================================================

*Target 1:最大化吞吐率*

假定 n 个分配和释放请求的某种序列：
`R_1, R_2, R_3, ..., R_k, ..., R_n-1`

我们希望一个分配器的吞吐率最大化，**吞吐率定义为每个单位时间里完成的请求数**。
例如，如果一个分配器在 1 秒内完成 500 个分配请求和 500 个释放请求，那么它的吞吐率就是每秒 1000 次操作。
一般而言，我们可以通过使满足分配和释放请求的平均时间最小化来使吞吐率最大化。
正如我们会看到的，开发一个具有*合理性能*的分配器并不困难，所谓合理性能是指*一个分配请求的最糟运行时间与空闲块的数量成线性关系，而一个释放请求的运行时间是个常数*。

这段话中的“合理性能”是指动态内存分配器在处理分配和释放请求时的效率和性能特性。让我们逐个解释这些概念：

### 吞吐率

- **定义**：吞吐率是指每个单位时间内完成的请求数。它是衡量动态内存分配器性能的一个重要指标。
- **示例**：如果一个分配器在1秒内完成了500个分配请求和500个释放请求，那么它的吞吐率是每秒1000次操作。

### 最大化吞吐率

- **方法**：为了最大化吞吐率，需要尽可能减少处理每个分配和释放请求所需的平均时间。
- **平均时间**：这包括从可用内存中找到合适的块、标记为已分配或释放，以及更新任何必要的内存管理数据结构的时间。

### 合理性能

- **定义**：所谓的“合理性能”是指分配器在处理请求时的效率特征。
- **分配请求的运行时间**：一个分配请求的最糟糕运行时间与空闲块的数量成线性关系。这意味着分配请求所需的时间与堆中空闲块的数量成正比。也就是说，空闲块越多，查找合适块的时间可能越长。
- **释放请求的运行时间**：一个释放请求的运行时间是个常数。这意味着无论堆的大小或空闲块的数量如何，释放内存所需的时间都是固定的。

### 重要性

- **效率和预测性**：具有合理性能的分配器提供了一定程度的效率和预测性。尽管在最坏情况下分配时间可能随空闲块的增加而增加，但释放操作的恒定时间提供了性能保证。
- **实用性**：在实际应用中，这种分配器性能通常被认为是可接受的，特别是在不需要极端优化的情况下。

### 结论

在设计内存分配器时，合理性能意味着分配器能够以预测的方式相对高效地处理分配和释放请求。
虽然最糟糕情况下的分配时间可能随着空闲块数量的增加而增长，但对于许多应用来说，这种性能水平是足够的。
同时，保持释放请求的恒定运行时间有助于确保分配器的总体性能和可用性。
====================================================================================================


*Target 2:最大化内存利用率*
天真的程序员经常不正确地假设虚拟内存是一个无限的资源。
实际上，一个系统中被所有进程分配的虚拟内存的全部数量是受磁盘上交换空间的数量限制的。
**好的程序员知道虚拟内存是一个有限的空间，必须高效地使用**。
对于可能被要求分配和释放大块内存的动态内存分配器来说，尤其如此。

有很多方式来描述一个分配器使用堆的效率如何。在我们的经验中，最有用的标准是`峰值利用率`（`peak utilization`）。
像以前一样，我们给定 n 个分配和释放请求的某种顺序

`R_0, R_1, R_2, R_3, ..., R_k, ..., R_n-1`

如果一个应用程序请求一个 `p`字节的块，那么得到的已分配块的有效载荷（`payload`）是 `p` 字节。
在请求完成之后，聚集有效载荷（`aggregate payload`）表示为 `P_k`，为当前已分配的块的有效载荷之和，而`H_k`表示堆的当前的（单调非递减的）大小。

那么，前如 k+1 个请求的峰值利用率，表示为 U_k 可以通过下式得到：
`U_k = max_{i<=k}(P_i) / H_k`

那么，分配器的目标就是在整个序列中使峰值利用率 `U_n-1` 最大化。正如我们将要看到的，在最大化吞吐率和最大化利用率之间是互相牵制的。
特别是，以堆利用率为代价，很容易编写出吞吐率最大化的分配器。
分配器设计中一个有趣的挑战就是在两个目标之间找到一个适当的平衡。

====================================================================================================
`峰值利用率`（`peak utilization`）是衡量动态内存分配器效率的一个重要标准。它基于应用程序在不同时间点的内存使用情况，来评估分配器对内存资源的利用效率。以下是对峰值利用率的详细解释：

### 定义

- **有效载荷（Payload）**：当应用程序请求一个特定大小的内存块时，有效载荷是指实际用于存储应用数据的内存大小。例如，如果请求了 `p` 字节，那么有效载荷就是 `p` 字节。
- **聚集有效载荷（Aggregate Payload）**：在任意给定时刻，所有已分配内存块的有效载荷之和。用 `P_k` 表示，在处理前 `k+1` 个请求（`R_0` 到 `R_k`）之后的聚集有效载荷。
- **堆大小（Heap Size）**：分配器维护的堆的当前大小。用 `H_k` 表示，它是单调非递减的，意味着随着时间的推移，堆的大小只会增加或保持不变。

### 峰值利用率计算

- 峰值利用率是在处理一系列分配和释放请求后，已分配内存的有效载荷与堆大小的最大比率。
- 对于前 `k+1` 个请求，峰值利用率 `U_k` 计算公式为：`U_k = max_{i<=k}(P_i) / H_k`。
- 这意味着，我们在前 `k+1` 个请求中找到有效载荷之和最大的时刻 `i`，然后用这个最大的聚集有效载荷 `P_i` 除以当前堆大小 `H_k`，得到峰值利用率。

### 重要性

- 峰值利用率衡量了在特定的请求序列中，分配器对堆内存的最高利用效率。
- 高峰值利用率意味着分配器能够在较小的堆空间内满足较大的内存需求，表明分配器在内存管理方面表现良好。
- 这是一个重要的性能指标，因为它反映了分配器在最糟糕情况下的表现。一个高峰值利用率的分配器能够更有效地使用内存资源，减少内存浪费。

总之，峰值利用率是评价动态内存分配器效率的一个关键指标，它有助于理解分配器在实际应用中的内存管理效能，特别是在处理复杂或不可预测的内存分配模式时的表现。


当然，让我用更通俗的方式来解释一下“峰值利用率”：

想象一下，你有一个仓库（这就是堆），用来存放各种箱子（这些箱子就是程序请求的内存块）。每个箱子有不同的大小，代表不同大小的内存请求。随着时间的推移，你会根据需要往仓库里添加或移出箱子。

1. **有效载荷**：就像每个箱子实际装的东西有多重，这就是每个内存块实际被使用的部分。

2. **聚集有效载荷**：假设你在某个时刻停下来看看仓库里所有箱子装的东西加起来有多重，这就是所有已分配内存块的总使用量。

3. **堆大小**：这就像仓库的容量。不过在我们的例子中，仓库的大小可以根据需要变大，但不能变小。

4. **峰值利用率**：这就像是在你观察仓库的整个历史过程中，找到那个装得最满的时刻，然后计算那时所有箱子装的东西的总重量占仓库容量的比例。

用这种方法衡量，如果你的仓库在大多数时间里都装得满满的，那么就意味着你利用空间非常高效。如果仓库大部分时间都半空不满，那么就意味着空间利用率不高。在内存管理中，我们希望“仓库”（堆）的利用率尽可能高，这样就意味着我们用较小的空间做了更多的事情，减少了资源浪费。
====================================================================================================

> 旁注 - 放宽单调性假设
> 我们可以通过让成为前k+1个请求的最高峰，从而使得在我们对U_k的定义中放宽单调非递减的假设，并且允许堆增长和降低。

We could relax the monotonically nondecreasing assumption in our definition of `Uk` and allow the heap
to grow up and down by letting `Hk` be the high-water mark over the first `k + 1` requests.

这段话讨论的是对“峰值利用率”（`U_k`）定义中关于堆大小的假设进行放宽。原先的定义是基于一个单调非递减的堆大小（即堆大小只增不减）。
这里提出的改变是允许堆大小既可以增长也可以减小。让我们逐一解释这个观点：

### 原始假设
- 在原始定义中，`H_k`（在处理前 `k+1` 个请求后堆的大小）被假设为单调非递减。这意味着堆的大小只能保持不变或增加，但不能减少。

### 放宽单调性假设
- **放宽假设**：这句话提出的是一种更灵活的处理方式，即允许堆的大小随着请求的处理而增加或减小。
- **实际影响**：这意味着堆不再只是不断增长，而是可以根据实际的内存使用情况进行调整。
当一些内存块被释放后，堆的大小可以减小，反映出释放出的内存。

### 对 `U_k` 的影响
- 在这种新的假设下，峰值利用率 `U_k` 的计算仍然是寻找有效载荷（`P_i`）与堆大小（`H_k`）之间的最大比率，但现在 `H_k` 可以根据实际情况增长或减小。
- 这种方式可能更真实地反映了分配器对内存的实际使用情况，特别是在那些频繁分配和释放内存的应用程序中。

### 结论
放宽单调性假设使得堆的大小可以更灵活地反应程序的内存使用模式。
它允许堆在不需要时收缩，从而可能提高内存利用率，尤其是在那些内存使用具有高动态性的应用中。
这种方法在评估内存分配器的性能时可能提供更加准确的洞察。
====================================================================================================

# 碎片
造成堆利用率很低的主要原因是一种称为碎片（`fragmentation`）的现象，当虽然有未使用的内存但不能用来满足分配请求时，就发生这种现象。
有两种形式的碎片：内部碎片（`internal fragmentation`）和外部碎片（`external fragmentation`）。

**内部碎片**是在一个已分配块比有效载荷大时发生的。

很多原因都可能造成这个问题。例如，一个分配器的实现可能对已分配块强加一个最小的大小值，而这个大小要比某个请求的有效载荷大。
或者，就如我们在图 9-34b 中看到的，分配器可能增加块大小以满足对齐约束条件。

内部碎片的量化是简单明了的。它就是*已分配块大小*和它们的*有效载荷大小*之差的和。
因此，在任意时刻，内部碎片的数量只取决于*以前请求的模式*和*分配器的实现方式*。


**外部碎片**是当空闲内存合计起来足够满足一个分配请求，但是没有一个单独的空闲块足够大可以来处理这个请求时发生的。

例如，如果图 9-34e 中的请求要求 6 个字，而不是 2 个字，那么如果不向内核请求额外的虚拟内存就无法满足这个请求，即使在堆中仍然有 6 个空闲的字。问题的产生是由于这 6 个字是分在两个空闲块中的。

外部碎片比内部碎片的量化要困难得多，因为它不仅取决于`以前请求的模式`和`分配器的实现方式`，还取决于`将来请求的模式`。
例如，假设在 k 个请求之后，所有空闲块的大小都恰好是 4 个字。这个堆会有外部碎片吗？答案取决于将来请求的模式。
如果将来所有的分配请求都要求小于或者等于 4 个字的块，那么就不会有外部碎片。另一方面，如果有一个或者多个请求要求比 4 个字大的块，那么这个堆就会有外部碎片。

因为外部碎片难以量化且不可能预测，所以分配器通常釆用**启发式策略**来试图维持少量的大空闲块，而不是维持大量的小空闲块。

内部碎片和外部碎片都是内存管理中的概念，特别是在讨论动态内存分配时。这两种碎片现象是导致内存利用率低下的主要原因。让我通俗地解释一下这两个概念：

### 内部碎片（Internal Fragmentation）

想象一下，你要装一些小东西到一个大盒子里。如果盒子比你需要的空间大很多，盒子里就会有很多未被使用的空间。这就是内部碎片。

在内存管理中，当分配给程序的内存块比实际需要的要大时，就会出现内部碎片。这通常发生在内存分配系统为了对齐或其他原因而分配比请求更大的内存块时。

- **例子**：如果一个程序请求100字节的内存，但分配器由于某些对齐规则，给它分配了128字节的块，那么多出的28字节就是内部碎片。

### 外部碎片（External Fragmentation）

现在想象一下，你的房间里有很多小空间可以用来存放东西，但没有一个空间是足够大的，能完整地放下一个大行李箱。这就是外部碎片。

在内存管理中，外部碎片是指堆中散布的、未被使用的小内存块。这些内存块本身总量可能很大，但由于它们分散且每个都很小，无法满足较大的内存分配请求。

- **例子**：如果堆中有许多小的空闲内存块，但每个都不足以满足一个大的内存请求，这就是外部碎片。

### 碎片的影响

- **内部碎片**：导致内存浪费，因为分配的内存块有未使用的部分。
- **外部碎片**：影响内存分配的效率，即使有足够的总空闲内存，也可能无法满足大的内存请求。
- **处理方法**：通常需要在内部和外部碎片之间寻找平衡。内存分配算法（如最佳适配、最坏适配、首次适配等）尝试以不同的方式减少这两种形式的碎片。

总的来说，内部碎片和外部碎片都是内存分配过程中的副作用，影响内存的有效利用。
理解这两种碎片以及如何在不同的场景下处理它们，对于实现高效的内存管理至关重要。
====================================================================================================

# 实现问题
可以想象出的最简单的分配器会把堆组织成一个大的字节数组，还有一个指针 `p`，初始指向这个数组的第一个字节。为了分配 `size` 个字节，`malloc` 将 `p` 的当前值保存在栈里，将 `p` 增加 `size`，并将 `p` 的旧值返回到调用函数。`free` 只是简单地返回到调用函数，而不做其他任何事情。

这个简单的分配器是设计中的一种极端情况。因为每个 `malloc` 和 `free` 只执行很少量的指令，吞吐率会极好。
然而，因为分配器从不重复使用任何块，内存利用率将极差。

一个实际的分配器要在`吞吐率`和`利用率`之间把握好平衡，就必须考虑以下几个问题：
- *空闲块组织*：我们如何记录空闲块？
- *放置*：我们如何选择一个合适的空闲块来放置一个新分配的块？
- *分割*：在将一个新分配的块放置到某个空闲块之后，我们如何处理这个空闲块中的剩余部分？
- *合并*：我们如何处理一个刚刚被释放的块？

本节剩下的部分将更详细地讨论这些问题。因为像`放置`、`分割`以及`合并`这样的基本技术贯穿在`许多不同的空闲块组织`中，所以我们将在一种叫做*隐式空闲链表*的*简单空闲块组织*结构中来介绍它们。

# 隐式空闲链表
任何实际的分配器都需要一些数据结构，允许它来区别`块边界`，以及区别`已分配块`和`空闲块`。大多数分配器将这些信息嵌入块本身。
一个简单的方法如图 9-35 所示。
~~~shell
            31 ......  3  2 1 0
            [   块大小  ][ 0 0 a] (a = 1: 已分配的， a = 0: 空闲的) 块大小包括所有的有效载荷和填充
   malloc ->[                  ]
            [      有效载荷     ]
            [   只包括已分配的块 ]
            [                  ]
            [------------------]
            [-----填充(可选)----]
            [------------------]
            
一个简单的堆块的格式
~~~ 

在这种情况中，一个块是由一个字的头部、有效载荷，以及可能的一些额外的填充组成的。
头部编码了这个块的大小（包括头部和所有的填充），以及这个块是已分配的还是空闲的。
如果我们强加一个双字的对齐约束条件，那么块大小就总是 8 的倍数，且块大小的最低 3 位总是零。
因此，我们只需要内存大小的 29 个高位，释放剩余的 3 位来编码其他信息。
在这种情况中，我们用其中的最低位（已分配位）来指明这个块是已分配的还是空闲的。

例如，假设我们有一个已分配的块，大小为 `24（0x18）`字节。那么它的头部将是
`0x00000018 | 0x1 = 0x00000019`

类似地，一个块大小为 40（0x28）字节的空闲块有如下的头部：
`0x00000028 | 0x0 = 0x00000028`

头部后面就是应用调用 `malloc` 时请求的有效载荷。有效载荷后面是一片不使用的填充块，其大小可以是任意的。
需要填充有很多原因。比如，填充可能是分配器策略的一部分，用来对付外部碎片。或者也需要用它来满足对齐要求。

假设块的格式如图 9-35 所示，我们可以将堆组织为一个连续的已分配块和空闲块的序列，如图 9-36 所示。
https://hansimov.gitbook.io/csapp/part2/ch09-virtual-memory/9.9-dynamic-memory-allocation#9.9.5-shi-xian-wen-ti
图 9-36 用隐式空闲链表来组织堆。阴影部分是已分配块。没有阴影的部分是空闲块。头部标记为（大小（字节）/ 已分配位）

我们称这种结构为`隐式空闲链表`，是因为空闲块是通过头部中的大小字段隐含地连接着的。
分配器可以通过遍历堆中所有的块，从而间接地遍历整个空闲块的集合。*注意，我们需要某种特殊标记的结束块，在这个示例中，就是一个设置了已分配位而大小为零的终止头部*（terminating header）。（就像我们将在 9.9.12 节中看到的，设置已分配位简化了空闲块的合并。）

隐式空闲链表的优点是简单。显著的缺点是任何操作的开销，例如放置分配的块，要求对空闲链表进行搜索，该搜索所需时间与堆中已分配块和空闲块的总数呈线性关系。

很重要的一点就是意识到系统对齐要求和分配器对块格式的选择会对分配器上的最小块大小有强制的要求。
没有已分配块或者空闲块可以比这个最小值还小。
例如，如果我们假设一个双字的对齐要求，那么每个块的大小都必须是双字（8 字节）的倍数。
因此，图 9-35 中的块格式就导致最小的块大小为两个字：一个字作头，另一个字维持对齐要求。即使应用只请求一字节，分配器也仍然需要创建一个两字的块。

====================================================================================================
隐式空闲链表是一种在动态内存分配中常用的数据结构，用于管理可用的内存块。它的工作原理和特点可以从以下几个方面来详细介绍：

### 工作原理
1. **内存块组织**：在隐式空闲链表中，内存被分为一系列的块。每个块都有一个头部（header），通常包含了块的大小和这个块是否被占用的信息。块的剩余部分是有效载荷（payload），即实际可用于存储数据的部分。
2. **链表结构**：这种链表被称为“隐式”的，因为链表的连接信息并不是直接存储为指针，而是隐含在每个块的大小信息中。即通过遍历内存块，查看每个块的大小和占用状态，来确定哪些块是空闲的。
3. **查找空闲块**：当分配内存时，分配器会从头开始遍历内存块，寻找足够大的空闲块。这个过程被称为首次适应（first-fit）或最佳适应（best-fit）等策略，具体取决于查找和选择空闲块的具体算法。
4. **分割块**：如果找到的空闲块大于所需大小，它将被分割。一部分被分配出去，剩余部分仍然标记为空闲。
5. **合并空闲块**：为了避免碎片化，当块被释放时，分配器会检查相邻的块，如果相邻的块也是空闲的，则会将它们合并成一个更大的空闲块。

### 特点
1. **高效率**：隐式链表在内存利用率方面相对高效，因为它不需要额外的数据结构来维护空闲块的信息。
2. **内存碎片化**：隐式链表可能导致内存碎片化问题，特别是在频繁分配和释放小块内存的场景中。
3. **查找效率**：查找合适空闲块的效率可能不是很高，特别是当空闲块较少或内存碎片化严重时，因为需要遍历整个链表。
4. **无额外开销**：与显式链表相比，隐式链表不需要额外的指针来连接空闲块，因此可以节约一些内存空间。

### 应用场景
隐式空闲链表适用于内存分配需求较为简单、内存碎片化问题不是主要关注点的场景。
在更复杂或对性能要求更高的应用中，可能需要采用更高级的内存管理技术，如显式链表、分离适配（`segregated fit`）或伙伴系统（`buddy system`）。
====================================================================================================

确定下面 malloc 请求序列产生的块大小和头部值。假设：
1）分配器保持双字对齐，并且使用块格式如图 9-35 中所示的隐式空闲链表。
2）块大小向上舍入为最接近的 8 字节的倍数。

请求            块大小（十进制）      块头部（十六进制）
`malloc(1)`     8                  0x9
`malloc(5)`     16                 0x11
`malloc(12)`    16                 0x11
`malloc(13)`    24                 0x9

这道题触及了一些核心的概念，例如对齐要求、最小块大小以及头部编码。
确定块大小的一般方法是，将所请求的有效载荷和头部大小的和舍入到对齐要求（在此例中是 8 字节）最近的整数倍。
比如，malloc(1) 请求的块大小是 4+1=5，然后舍入到 8。而 malloc(13) 请求的块大小是 13+4=17，舍入到 24。

# 放置已分配的块
当一个应用请求一个互字节的块时，分配器搜索空闲链表，查找一个足够大可以放置所请求块的空闲块。
分配器执行这种搜索的方式是由放置策略（`placement policy`）确定的。一些常见的策略是首次适配（*firstfit*），下一次适配（*nextfit*）和最佳适配（*bestfit*）„

当一个应用请求一定大小的内存时（比如一个八字节的块），内存分配器的任务就是在可用内存中找到一个合适的空间来满足这个请求。这就像你在一个有很多不同大小房间的大楼里寻找一个能够容纳你特定物品的空房间。分配器如何决定选择哪个“房间”就是由所谓的“放置策略”决定的。
下面是三种常见的放置策略，我们可以用简单的比喻来理解它们：

1. **首次适配（First-fit）**:
   - 想象你正在走在一条长走廊里，寻找第一个足够大的房间来放置你的物品。
   - 在内存分配中，分配器查找内存的第一个空闲块，该块大到足以满足请求的大小。一旦找到，就使用这个块，即使后面可能有更合适的（比如更小但仍足够大的块）。

2. **下一次适配（Next-fit）**:
   - 类似于首次适配，但这里你会记住上次找到房间的位置。下次你再寻找空间时，会从上次找到的地方开始，而不是从走廊的开头开始。
   - 在内存分配中，这意味着分配器从上一次搜索结束的地方开始搜索，而不是每次都从头开始。这可以加快搜索速度，但也可能导致内存的不同部分被不均匀地使用。

3. **最佳适配（Best-fit）**:
   - 在这种情况下，你会检查整个大楼的每一个房间，直到找到最合适的那一个——既能放下你的物品，又不会太大，以免浪费空间。
   - 对于内存分配，这意味着分配器会检查每个空闲块，并选择最接近请求大小的块。这种方法可以减少空间浪费，但可能需要更长时间来搜索整个内存，特别是当内存碎片化时。

每种策略都有其优势和劣势。首次适配和下一次适配通常更快，因为它们不需要检查所有空闲块，但可能会导致更多的内存碎片。
最佳适配虽然可以减少碎片，但搜索过程可能更慢，特别是在内存使用频繁的情况下。在实际应用中，选择哪种策略取决于具体需求和性能考虑。

首次适配从头开始搜索空闲链表，选择第一个合适的空闲块。下一次适配和首次适配很相似，只不过不是从链表的起始处开始每次搜索，而是从上一次查询结束的地方开始。最佳适配检查每个空闲块，选择适合所需请求大小的最小空闲块。

首次适配的优点是它趋向于将大的空闲块保留在链表的后面。缺点是它趋向于在靠近链表起始处留下小空闲块的“碎片”，这就增加了对较大块的搜索时间。
下一次适配是由 Donald Knuth 作为首次适配的一种代替品最早提出的，源于这样一个想法：*如果我们上一次在某个空闲块里已经发现了一个匹配，那么很可能下一次我们也能在这个剩余块中发现匹配*。
下一次适配比首次适配运行起来明显要快一些，尤其是当链表的前面布满了许多小的碎片时。然而，一些研究表明，下一次适配的内存利用率要比首次适配低得多。
研究还表明最佳适配比首次适配和下一次适配的内存利用率都要高一些。然而，在简单空闲链表组织结构中，比如隐式空闲链表中，使用最佳适配的缺点是它要求对堆进行彻底的搜索。在后面，我们将看到更加精细复杂的*分离式空闲链表组织*，它接近于最佳适配策略，不需要进行彻底的堆搜索。

# 分割空闲块

一旦分配器找到一个匹配的空闲块，它就必须做另一个策略决定，那就是分配这个空闲块中多少空间。一个选择是用整个空闲块。虽然这种方式简单而快捷，但是主要的缺点就是它会造成内部碎片。如果放置策略趋向于产生好的匹配，那么额外的内部碎片也是可以接受的。

然而，如果匹配不太好，那么分配器通常会选择将这个空闲块分割为两部分。第一部分变成分配块，而剩下的变成一个新的空闲块。
图 9-37 展示了分配器如何分割图 9-36 中 8 个字的空闲块，来满足一个应用的对堆内存 3 个字的请求。

# 获取额外的堆内存

如果分配器不能为请求块找到合适的空闲块将发生什么呢？
一个选择是通过合并那些在内存中物理上相邻的空闲块来创建一些更大的空闲块（在下一节中描述）。
然而，如果这样还是不能生成一个足够大的块，或者如果空闲块已经最大程度地合并了，那么分配器就会通过调用 `sbrk` 函数，向内核请求额外的堆内存。
分配器将额外的内存转化成一个大的空闲块，将这个块插入到空闲链表中，然后将被请求的块放置在这个新的空闲块中。

# 合并空闲块

当分配器`释放`一个已分配块时，可能有其他空闲块与这个新释放的空闲块相邻。这些邻接的空闲块可能引起一种现象，叫做`假碎片`（*fault fragmentation*），就是有许多可用的空闲块被切割成为小的、无法使用的空闲块。比如，图 9-38 展示了释放图 9-37 中分配的块后得到的结果。结果是两个相邻的空闲块，每一个的有效载荷都为 3 个字。因此，接下来一个对 4 字有效载荷的请求就会失败，即使两个空闲块的合计大小足够大，可以满足这个请求。

为了解决假碎片问题，任何实际的分配器都必须合并相邻的空闲块，这个过程称为**合并（coalescing）**。
这就出现了一个重要的策略决定，那就是*何时执行合并*。
分配器可以选择立即*合并*（immediate coalescing），也就是在每次一个块被释放时，就合并所有的相邻块。
或者它也可以选择推迟合并（*deferred coalescing*），也就是等到某个稍晚的时候再合并空闲块。例如，分配器可以推迟合并，直到某个分配请求失败，然后扫描整个堆，合并所有的空闲块。

立即合并很简单明了，可以在常数时间内执行完成，但是对于某些请求模式，这种方式会产生一种形式的抖动，块会反复地合并，然后马上分割。
例如，在图 9-38 中，反复地分配和释放一个 3 个字的块将产生大量不必要的分割和合并。
在对分配器的讨论中，我们会假设使用立即合并，*但是你应该了解，快速的分配器通常会选择某种形式的推迟合并*。

合并（coalescing）是内存分配器用来解决内存碎片化问题的一种策略。在讨论合并时，一个关键的决策点是决定何时执行合并操作。主要有两种策略：立即合并（immediate coalescing）和推迟合并（deferred coalescing）。让我们来探讨这两种策略的特点和适用情况：

### 立即合并（Immediate Coalescing）

1. **操作方式**：当一个内存块被释放时，分配器立刻检查相邻的块，如果发现相邻的块也是空闲的，则立即将它们合并成一个更大的空闲块。
2. **优点**：这种方法可以快速减少内存碎片，保持内存的整洁度。由于是立即执行，它可以确保内存空间的最大化利用。
3. **缺点**：在某些情况下，可能会导致效率低下。例如，如果有一个内存块频繁地被分配和释放，那么每次释放后立即合并再分配可能会导致所谓的“抖动”现象——频繁的合并和分割操作。

### 推迟合并（Deferred Coalescing）

1. **操作方式**：在这种策略下，分配器不会在块被释放时立即合并空闲块。相反，它会等待，直到出现内存分配问题（如无法满足内存请求）或特定条件触发时，才对整个内存堆进行一次扫描，合并所有相邻的空闲块。
2. **优点**：这种方法可以减少由于频繁合并和分割导致的开销，特别是在内存分配和释放操作非常频繁的情况下。
3. **缺点**：推迟合并可能会导致短期内的内存碎片化增加，因为不是立即清理空闲空间。这可能暂时减少可用的连续内存块，从而影响内存分配效率。

### 策略选择

在实践中，不同的分配器根据具体应用的内存分配和释放模式选择最适合的合并策略。高性能的分配器可能会采用一种更加复杂的策略，比如结合立即合并和推迟合并的特点，以在减少碎片和避免抖动之间找到平衡点。例如，它们可能在检测到内存碎片化达到某个阈值时执行合并操作，或者在特定时间间隔后进行一次全面的内存合并。这样可以更灵活地适应不同的内存使用模式，从而提高整体的内存管理效率。

# 带边界标记的合并

**分配器是如何实现合并的？**
让我们称想要释放的块为当前块。那么，合并（内存中的）下一个空闲块很简单而且高效。
当前块的头部指向下一个块的头部，可以检查这个指针以判断下一个块是否是空闲的。
如果是，就将它的大小简单地加到当前块头部的大小上，这两个块在常数时间内被合并。

====================================================================================================
您描述的是内存管理中的一种具体的合并（coalescing）技术，用于处理连续内存块的释放和合并。这种方法的目标是减少内存碎片化，通过合并相邻的空闲块来创建更大的连续空间。让我们详细解释这个过程：

### 合并下一个空闲块的过程

1. **识别当前块**：当应用决定释放一个内存块时，这个块成为“当前块”。释放操作通常涉及将该块标记为不再被使用，即变为一个空闲块。
2. **检查相邻的下一个块**：当前块的头部通常包含了指向下一个块的指针或者信息，可以用来确定下一个块的位置以及它的状态（是否为空闲）。
3. **判断下一个块的状态**：如果下一个块也是空闲的，这表示两个连续的内存块都是未被使用的，可以进行合并。
4. **合并操作**：
   - **更新大小信息**：将下一个空闲块的大小加到当前块的大小上。这样，当前块的大小就更新为两个块的总和。
   - **调整头部信息**：更新当前块的头部信息，确保它反映了合并后的新大小。
5. **常数时间操作**：这个合并操作是高效的，因为它不涉及实际的数据移动或复杂的计算。它仅仅是更新了一些内存块头部的元数据。

### 优势和重要性
- **减少碎片化**：通过合并相邻的空闲块，这种方法有效地减少了内存的碎片化，从而使得更大的连续内存块可用于未来的分配请求。
- **提高内存利用率**：合并后的较大空闲块可以更有效地满足大型内存请求，减少了因碎片化导致的内存浪费。
- **高效率**：由于操作仅限于更新头部信息，因此执行速度快，对系统性能的影响最小。

总的来说，这种合并技术是内存管理中的一个关键组成部分，帮助提高了内存利用效率和系统性能。
尽管它在处理连续内存释放时非常有效，但它也依赖于内存使用模式，以及分配器的其他特性和策略。
====================================================================================================

*但是我们该如何合并前面的块呢？*
给定一个带头部的隐式空闲链表，唯一的选择将是搜索整个链表，记住前面块的位置，直到我们到达*当前块*。
使用隐式空闲链表，这意味着每次调用 free 需要的时间都与堆的大小成线性关系。即使使用更复杂精细的空闲链表组织，搜索时间也不会是常数。

====================================================================================================
合并前一个空闲块在隐式空闲链表中的确是一个更复杂的过程，主要因为在这种链表结构中，块之间没有显式的指向前一个块的指针。
让我们探讨一下这个过程和它的挑战：

### 合并前一个空闲块的挑战

1. **无前向指针**：在隐式空闲链表中，每个块通常只包含有关其自身大小和状态的信息。与显式链表不同，隐式链表中的块不包含指向前一个块的指针。
2. **搜索整个链表**：为了找到当前块的前一个块，分配器必须从堆的开始处遍历整个链表，直到找到紧邻当前块的前一个块。
3. **记住前一个块的位置**：在搜索过程中，分配器需要记住每个遍历过的块的位置，以便在到达当前块时能够识别其前一个块。
4. **时间复杂度**：这种搜索过程的时间复杂度是线性的，即它与堆的总大小成正比。这意味着，对于较大的堆，这个过程可能会相对耗时。

### 合并操作

1. **确定前一个块是否为空闲**：一旦找到前一个块，分配器需要检查它是否为空闲。
2. **执行合并**：如果前一个块是空闲的，那么可以将当前块和前一个块合并。这涉及到更新前一个块的头部信息以反映合并后的新大小。

### 可能的优化

虽然使用隐式空闲链表进行前向合并在时间上不是最高效的，但仍然有一些策略可以在一定程度上优化这个过程：

- **较少的分配和释放操作**：如果内存的分配和释放操作不是非常频繁，这种线性时间的开销可能是可接受的。
- **较小的堆大小**：对于较小的堆，遍历整个链表的成本较低。
- **使用双向链表或其他结构**：虽然这不再是传统意义上的“隐式”链表，但在某些情况下，引入额外的结构（如双向链表或其他元数据）可以提高前向合并的效率。
- **合并策略**：采用合适的合并策略，例如仅在发现内存碎片化达到一定程度时才执行合并，可以减少不必要的合并操作。

总的来说，合并前一个空闲块在隐式空闲链表中确实是一个更耗时的操作，但通过合理的内存管理策略和可能的数据结构调整，可以在一定程度上缓解这个问题。
====================================================================================================

Knuth 提出了一种聪明而通用的技术，叫做边界标记（`boundary tag`），允许在常数时间内进行对前面块的合并。
这种思想，如图 9-39 所示，是在每个块的结尾处添加一个脚部（`footer`，边界标记），其中脚部就是头部的一个副本。
如果每个块包括这样一个脚部，那么分配器就可以通过检査它的脚部，*判断前面一个块的起始位置和状态*，这个脚部总是在距当前块开始位置一个字的距离。

~~~shell
            31 ......  3  2 1 0
            [   块大小  ][ 0 0 a] (a = 1: 已分配的， a = 0: 空闲的) 块大小包括所有的有效载荷和填充
   malloc ->[                  ]
            [      有效载荷     ]
            [   只包括已分配的块 ]
            [                  ]
            [------------------]
            [-----填充(可选)----]
            [------------------]
            [   块大小  ][ a / f]
~~~
图：使用边界标记的堆块的格式

====================================================================================================
PS
Donald Knuth 提出的边界标记技术是内存分配和管理中的一个重要概念。这种方法通过在每个内存块的末尾添加一个脚部（`footer`），来允许快速地合并相邻的空闲块。这个脚部实际上是内存块头部（header）的一个副本，包含了关于该内存块的信息，如其大小和分配状态。

在这种设计中，每个内存块都包含两个主要部分：一个头部和一个脚部。
头部位于块的开始处，通常包含了内存块的大小和分配状态。相应地，脚部位于块的末尾，复制头部的信息。

这种布局的优势在于，当内存分配器需要释放或重新分配内存时，它可以通过检查当前块的脚部来快速识别和访问前一个块。
由于脚部包含了前一个块的大小和状态信息，分配器可以判断前一个块是否空闲，以及它的起始位置。
如果前一个块是空闲的，分配器可以将这两个块合并为一个更大的块，这个过程称为合并（coalescing）。
====================================================================================================

考虑当分配器释放当前块时所有可能存在的情况：
1. 前面的块和后面的块都是已分配的。
2. 前面的块是已分配的，后面的块是空闲的。
3. 前面的块是空闲的，而后面的块是已分配的。
4. 前面的和后面的块都是空闲的。
图 9-40 展示了我们如何对这四种情况进行合并。

https://hansimov.gitbook.io/csapp/part2/ch09-virtual-memory/9.9-dynamic-memory-allocation#9.9.11-dai-bian-jie-biao-ji-de-he-bing

- 在情况 1 中，两个邻接的块都是已分配的，因此不可能进行合并。所以当前块的状态只是简单地从已分配变成空闲。
- 在情况 2 中，当前块与后面的块合并。用当前块和后面块的大小的和来更新当前块的头部和后面块的脚部。
- 在情况 3 中，前面的块和当前块合并。用两个块大小的和来更新前面块的头部和当前块的脚部。
- 在情况 4 中，要合并所有的三个块形成一个单独的空闲块，用三个块大小的和来更新前面块的头部和后面块的脚部。在每种情况中，合并都是在常数时间内完成的。

边界标记的概念是简单优雅的，它对许多不同类型的分配器和空闲链表组织都是通用的。
然而，它也存在一个潜在的缺陷。它要求每个块都保持一个头部和一个脚部，在应用程序操作许多个小块时，会产生显著的内存开销。
例如，如果一个图形应用通过反复调用 malloc 和 free 来动态地创建和销毁图形节点，并且每个图形节点都只要求两个内存字，那么头部和脚部将占用每个已分配块的一半的空间。

幸运的是，有一种非常聪明的边界标记的优化方法，能够使得在已分配块中不再需要脚部。

回想一下，当我们试图在内存中合并当前块以及前面的块和后面的块时，只有在前面的块是空闲时，才会需要用到它的脚部。如果我们把前面块的`已分配/空闲位`存放在当前块中多出来的低位中，那么已分配的块就不需要脚部了，这样我们就可以将这个多出来的空间用作有效载荷了。不过请注意，空闲块仍然需要脚部。
====================================================================================================
PS
1. **对于已分配的块**：通常情况下，每个内存块都需要一个头部和一个脚部。
头部包含了块的大小和分配状态信息，而脚部是头部的副本，用于合并操作。在您的方法中，对于已分配的块，您建议将“已分配/空闲位”存放在当前块的低位中。
这样，已分配的块就不再需要一个脚部，因为合并操作只在空闲块之间进行。将脚部省略掉可以将这部分内存用于存储有效数据（有效载荷），从而提高空间利用率。

2. **对于空闲的块**：空闲块仍然需要脚部，因为当合并内存块时，需要知道前一个块的状态和大小。
如果前一个块是空闲的，那么就可以将这两个块合并成一个更大的块，这需要访问前一个块的脚部来确定其大小和状态。

通过这种方法，您可以减少内存碎片化，提高内存利用率。在已分配的块中省去脚部，可以为实际的有效载荷提供更多空间。
同时，通过保留空闲块的脚部，您保持了合并空闲块的能力，这对于有效管理内存非常关键。
这种设计是内存管理中的一种平衡，旨在最大限度地减少内存的浪费，同时保持管理的灵活性和效率。

让我们通过一个具体的例子来阐述这种内存管理技术。假设我们有一段连续的内存，由多个内存块组成，每个块可能是已分配的或空闲的。我们使用头部和脚部来标记这些块，并在合并空闲块时利用这些信息。以下是一个简化的示例：

### 初始状态
- 假设有三个连续的内存块：块A、块B和块C。
- 每个块都有一个头部，其中包含块的大小和分配状态（已分配或空闲）。
- 根据您的方法，仅空闲块需要脚部。

### 块的状态
- 块A：已分配，大小为10字节。
- 块B：空闲，大小为20字节。
- 块C：已分配，大小为15字节。

### 内存布局
- **块A（已分配）**: 头部（包含大小和已分配标记）。没有脚部，因为它是已分配的。
- **块B（空闲）**: 头部（包含大小和空闲标记）+ 空闲内存 + 脚部（复制头部信息）。
- **块C（已分配）**: 头部（包含大小和已分配标记）。没有脚部，因为它是已分配的。

### 合并操作
- 现在，假设块C被释放，成为一个空闲块。
- 此时，块B和块C都是空闲的，可以被合并。
- 合并后，新的空闲块（假设为块D）的大小是块B和块C的大小之和。
- 块D现在有一个新的头部和脚部，反映了合并后的总大小。

### 合并后的布局
- **块A（已分配）**: 未变。
- **块D（空闲）**: 新头部（包含合并后的大小和空闲标记）+ 合并后的空闲内存 + 新脚部（复制头部信息）。

这个例子展示了如何在内存块被释放和合并时管理头部和脚部。已分配块不需要脚部，节省了空间；而空闲块的脚部使得合并操作成为可能。通过这种方式，可以更有效地管理内存，减少浪费。
====================================================================================================

# ⭐ 综合：实现一个简单的分配器 ⭐

构造一个分配器是一件富有挑战性的任务。
设计空间很大，有多种块格式、空闲链表格式，以及放置、分割和合并策略可供选择。
另一个挑战就是你经常被迫在类型系统的安全和熟悉的限定之外编程，依赖于容易出错的指针强制类型转换和指针运算，这些操作都属于典型的低层系统编程。

虽然分配器不需要大量的代码，但是它们也还是细微而不可忽视的。
熟悉诸如 C++ 或者 Java 之类高级语言的学生通常在他们第一次遇到这种类型的编程时，会遭遇一个概念上的障碍。为了帮助你清除这个障碍，我们将基于隐式空闲链表，使用立即边界标记合并方式，从头至尾地讲述一个简单分配器的实现。
最大的块大小为4GB (2^32)。代码是 64 位干净的，即代码能不加修改地运行在 32 位（gcc -m32）或 64 位（gcc -m64）的进程中。
The code is 64-bit clean, running without modification in 32-bit (gcc -m32) or 64-bit (gcc -m64) processes.

## *1. 通用分配器设计*
我们的分配器使用如图 9-41 所示的 memlib.c 包所提供的一个内存系统模型。模型的目的在于允许我们在不干涉已存在的系统层 malloc 包的情况下，运行分配器。

~~~c
// memlib.c：内存系统模型
/* Private global variables */
static char *mem_heap;     /* Points to first byte of heap */
static char *mem_brk;      /* Points to last byte of heap plus 1 */
static char *mem_max_addr; /* Max legal heap addr plus 1*/

/*
 * mem_init - Initialize the memory system model
 * This function sets up the initial state of the simulated memory system.
 * It allocates a large block of memory to represent the heap and initializes
 * the pointers that track the heap's start, current "break" (end), and maximum address.
 */
void mem_init(void)
{
    mem_heap = (char *)Malloc(MAX_HEAP); // Allocate the heap memory. MAX_HEAP defines the total size.
    mem_brk = (char *)mem_heap; // Initially, the break is at the start of the heap.
    mem_max_addr = (char *)(mem_heap + MAX_HEAP); // Set the max address to the end of the allocated heap.
}

/*
 * mem_sbrk - Simple model of the sbrk function. 
 * Extends the heap by incr bytes and returns the start address of the new area. 
 * In this model, the heap cannot be shrunk.
 *
 * Parameters:
 *    incr - the number of bytes to increase the heap by.
 *
 * Returns:
 *    A pointer to the start of the newly allocated heap area, or -1 on error.
 *
 * This function mimics the behavior of the Unix sbrk() system call. It increments
 * the simulated heap's break value (mem_brk) by 'incr' bytes and returns a pointer
 * to the previous break value, effectively allocating a block of 'incr' bytes on the heap.
 * If the increment is negative or if it exceeds the maximum heap size, the function
 * sets an error and returns -1.
 */
void *mem_sbrk(int incr)
{
    char *old_brk = mem_brk; // Store the old break value to return it later.

    // Check if the requested memory increase is valid.
    if ( (incr < 0) || ((mem_brk + incr) > mem_max_addr)) {
        errno = ENOMEM; // Set the error number to indicate memory allocation failure.
        fprintf(stderr, "ERROR: mem_sbrk failed. Ran out of memory...\n");
        return (void *) - 1; // Return -1 to indicate an error.
    }

    mem_brk += incr; // Increase the break value to allocate more memory.
    return (void *)old_brk; // Return the previous break value, marking the start of the newly allocated space.
}
~~~


`mem_init` 函数将对于堆来说可用的虚拟内存模型化为一个大的、双字对齐的字节数组。
在 `mem_heap` 和 `mem_brk` 之间的字节表示已分配的虚拟内存。`mem_brk` 之后的字节表示未分配的虚拟内存。
分配器通过调用 `mem_sbrk` 函数来请求额外的堆内存，这个函数和系统的 `sbrk` 函数的接口相同，而且语义也相同，*除了它会拒绝收缩堆的请求*。

分配器包含在一个源文件中（`mm.c`），用户可以编译和链接这个源文件到他们的应用之中。分配器输出三个函数到应用程序：

~~~c
extern int mm_init(void);
extern void *mm_malloc (size_t size);
extern void mm_free (void *ptr);
~~~

mm_init 函数初始化分配器，如果成功就返回 0，否则就返回 -1。
mm_malloc 和 mm_free 函数 与它们对应的系统函数有相同的接口和语义。
分配器使用如图 9-39 所示的块格式。最小块的大小为 16 字节。
空闲链表组织成为一个隐式空闲链表，具有如图 9-42 所示的恒定形式。
https://hansimov.gitbook.io/csapp/part2/ch09-virtual-memory/9.9-dynamic-memory-allocation#9.9.11-dai-bian-jie-biao-ji-de-he-bing

第一个字是一个双字边界对齐的不使用的填充字。
填充后面紧跟着一个特殊的序言块（`prologue block`），这是一个 8 字节的已分配块，只由一个头部和一个脚部组成。序言块是在初始化时创建的，并且永不释放。
在序言块后紧跟的是零个或者多个由 malloc 或者 free 调用创建的普通块。
堆总是以一个特殊的结尾块（`epilogue block`）来结束，这个块是一个大小为零的已分配块，只由一个头部组成。
序言块和结尾块是一种*消除合并时边界条件*的技巧。
分配器使用一个单独的私有（`static`）全局变量（`heap_listp`），它总是指向序言块。（作为一个小优化，我们可以让它指向下一个块，而不是这个序言块。）

# 2.操作空闲链表的基本常数和宏
图 9-43 展示了一些我们在分配器编码中将要使用的基本常数和宏。
第 2 ~ 4 行定义了一些基本的大小常数：字的大小（`WSIZE`）和双字的大小（`DSIZE`），初始空闲块的大小和扩展堆时的默认大小（CHUNKSIZE）。

~~~c
// mm.c
/* Basic constants and macros */
#define WSIZE 4             /* Word and header/footer size (bytes) */
#define DSIZE 8             /* Double word size (bytes) */
#define CHUNKSIZE (1<<12)   /* Extend heap by this amount (bytes) */

#define MAX(x, y) ((x) > (y)? (x) : (y))

/* Pack a size and allocated bit into a word */
#define PACK(size, alloc) ((size) | (alloc))

/* Read and write a word at address p */
#define GET(p)       (*(unsigned int *)(p))
#define PUT(p, val)  (*(unsigned int *)(p) = (val))

/* Read the size and allocated fields from address p */
#define GET_SIZE(p)  (GET(p) & ~0x7)
#define GET_ALLOC(p) (GET(p) & 0x1)

/* Given block ptr bp, compute address of its header and footer */
#define HDRP(bp)       ((char *)(bp) - WSIZE)
#define FTRP(bp)       ((char *)(bp) + GET_SIZE(HDRP(bp)) - DSIZE)

/* Given block ptr bp, compute address of next and previous blocks */
#define NEXT_BLKP(bp)  ((char *)(bp) + GET_SIZE(((char *)(bp) - WSIZE)))
#define PREV_BLKP(bp)  ((char *)(bp) - GET_SIZE(((char *)(bp) - DSIZE)))
~~~

~~~shell
            31 ......  3  2 1 0
            [   块大小  ][ 0 0 a] (a = 1: 已分配的， a = 0: 空闲的) 块大小包括所有的有效载荷和填充
   malloc ->[                  ]
            [      有效载荷     ]
            [   只包括已分配的块 ]
            [                  ]
            [------------------]
            [-----填充(可选)----]
            [------------------]
            [   块大小  ][ a / f]
~~~

Let's continue with the detailed comments for the provided C code, which appears to be part of a memory manager implementation:

```c
// mm.c

/* Basic constants and macros */

#define WSIZE 4             /* Word and header/footer size (bytes) */
#define DSIZE 8             /* Double word size (bytes) */
#define CHUNKSIZE (1<<12)   /* Extend heap by this amount (bytes) */

#define MAX(x, y) ((x) > (y)? (x) : (y))

/* Pack a size and allocated bit into a word */
#define PACK(size, alloc) ((size) | (alloc))

/* Read and write a word at address p */
#define GET(p)       (*(unsigned int *)(p))
#define PUT(p, val)  (*(unsigned int *)(p) = (val))

/* Read the size and allocated fields from address p */
#define GET_SIZE(p)  (GET(p) & ~0x7)
#define GET_ALLOC(p) (GET(p) & 0x1)

/* Given block ptr bp, compute address of its header and footer */
#define HDRP(bp)       ((char *)(bp) - WSIZE)
#define FTRP(bp)       ((char *)(bp) + GET_SIZE(HDRP(bp)) - DSIZE)

/* Given block ptr bp, compute address of next and previous blocks */
#define NEXT_BLKP(bp)  ((char *)(bp) + GET_SIZE(((char *)(bp) - WSIZE)))
#define PREV_BLKP(bp)  ((char *)(bp) - GET_SIZE(((char *)(bp) - DSIZE)))
```
在空闲链表中操作头部和脚部可能是很麻烦的，因为它要求大量使用强制类型转换和指针运算。
因此，我们发现定义一小组宏来访问和遍历空闲链表是很有帮助的（第 9 ~ 25 行）。
PACK 宏（第 9 行）将大小和已分配位结合起来并返回一个值，可以把它存放在头部或者脚部中。
`#define PACK(size, alloc) ((size) | (alloc))`

GET 宏（第 12 行）读取和返回参数 p 引用的字。这里强制类型转换是至关重要的。
参数 P 典型地是一个(viod*) 指针，不可以直接进行间接引用。
类似地，PUT 宏（第 13 行）将 val 存放在参数 p 指向的字中。
`#define GET(p)       (*(unsigned int *)(p))`
`#define PUT(p, val)  (*(unsigned int *)(p) = (val))`

GET_SIZE 和 GET_ALLOC 宏（第 16 ~ 17 行）从地址 p 处的头部或者脚部分别返回大小和已分配位。
`#define GET_SIZE(p)  (GET(p) & ~0x7)`
`#define GET_ALLOC(p) (GET(p) & 0x1)`

剩下的宏是对块指针（`block pointer`，用 bp 表示）的操作，**块指针指向第一个有效载荷字节**。
给定一个块指针 bp，HDRP 和 FTRP 宏（第 20 ~ 21 行）分别返回指向这个块的头部和脚部的指针。
`NEXT_BLKP` 和 `PREV_BLKP` 宏（第 24 ~ 25 行）分别返回指向后面的块和前面的块的块指针。
~~~c
/* Given block ptr bp, compute address of its header and footer */
#define HDRP(bp)       ((char *)(bp) - WSIZE)
#define FTRP(bp)       ((char *)(bp) + GET_SIZE(HDRP(bp)) - DSIZE)

/* Given block ptr bp, compute address of next and previous blocks */
#define NEXT_BLKP(bp)  ((char *)(bp) + GET_SIZE(((char *)(bp) - WSIZE)))
#define PREV_BLKP(bp)  ((char *)(bp) - GET_SIZE(((char *)(bp) - DSIZE)))
~~~

可以用多种方式来编辑宏，以操作空闲链表。
比如，给定一个指向当前块的指针 bp，我们可以使用下面的代码行来确定内存中后面的块的大小：
~~~c
size_t size = GET_SIZE(HDRP(NEXT_BLKP(bp)));
~~~

可以用多种方式来编辑宏，以操作空闲链表。比如，给定一个指向当前块的指针 bp，我们可以使用下面的代码行来确定内存中后面的块的大小：

- **Basic Constants and Macros**
  - `WSIZE`: Defines the size of a word, as well as the size of the header and footer in bytes. Typically, this is 4 bytes.
  - `DSIZE`: Defines the size of a double word, typically 8 bytes.
  - `CHUNKSIZE`: Defines the default size by which the heap is extended, set to 4096 bytes (1 << 12).
  - `MAX`: A simple macro for computing the maximum of two values.

- **Memory Block Utilities**
  - `PACK`: Combines a size and an allocated bit into a single word. This is used to store information in the header and footer of a memory block.
  - `GET` and `PUT`: Macros to read and write a word at a given pointer `p`. They are used to manipulate headers and footers of memory blocks.
  - `GET_SIZE` and `GET_ALLOC`: Extract the size and allocation bit from a word, respectively. These macros are used to interpret the contents of a block header or footer.

- **Pointer Arithmetic Macros**
  - `HDRP(bp)`: Given a block pointer `bp`, computes the address of its header. It steps back one word size from the given block pointer.
  - `FTRP(bp)`: Given a block pointer `bp`, computes the address of its footer. It finds the end of the block based on the size in the header and adjusts for the header and footer size.
  - `NEXT_BLKP(bp)`: Given a block pointer `bp`, computes the address of the next block. It moves forward from the current block by its size.
  - `PREV_BLKP(bp)`: Given a block pointer `bp`, computes the address of the previous block. It moves backward from the current block by the size of the block preceding it.

These definitions and macros are typical in a memory allocator implementation, where managing memory block sizes, allocation status, and navigating between blocks efficiently is crucial. 
The use of pointer arithmetic and bitwise operations allows for efficient manipulation of memory blocks within the heap.


## 3. 创建初始空闲链表

在调用 mm_malloc 或者 mm_free 之前，应用必须通过调用 mm_init 函数来初始化堆
~~~c
// mm.c - 创建带一个初始空闲块的堆
int mm_init(void)
{
    /* Create the initial empty heap */
    // Attempt to extend the heap by 4 words, and set the heap_listp to point to the first byte of this new area.
    // If the extension fails (mem_sbrk returns -1), return -1 to indicate an error in initialization.
    if ((heap_listp = mem_sbrk(4 * WSIZE)) == (void *) - 1)
        return -1;

    // Initialize the heap with its initial empty state.

    // First word is set to 0, serving as alignment padding. This is often necessary to ensure that the following 
    // blocks are aligned properly for the system architecture.
    PUT(heap_listp, 0);                            /* Alignment padding */

    // Next, set up the prologue block, which helps in coalescing and boundary conditions. 
    // This block is not actually a free or used block, but rather a placeholder.
    PUT(heap_listp + (1 * WSIZE), PACK(DSIZE, 1)); /* Prologue header */
    PUT(heap_listp + (2 * WSIZE), PACK(DSIZE, 1)); /* Prologue footer */

    // Finally, set up the epilogue header, which marks the end of the current heap.
    // The size is set to 0 and the allocated bit is set to 1, indicating that this is not a usable block.
    PUT(heap_listp + (3 * WSIZE), PACK(0, 1));     /* Epilogue header */

    // Move heap_listp past the prologue header for future heap extensions.
    heap_listp += (2 * WSIZE);

    /* Extend the empty heap with a free block of CHUNKSIZE bytes */
    // Attempt to extend the heap by CHUNKSIZE bytes to create the initial free block.
    // If the extension fails, return -1 to indicate an error.
    if (extend_heap(CHUNKSIZE / WSIZE) == NULL)
        return -1;

    // If initialization is successful, return 0.
    return 0;
}
~~~

`mm_init` 函数从内存系统得到 4 个字，并将它们初始化，创建一个空的空闲链表（第 4 ~ 10 行）。然后它调用 extend_heap 函数（图 9-45），这个函数将堆扩展 `CHUNKSIZE` 字节，并且创建初始的空闲块。此刻，分配器已初始化了，并且准备好接受来自应用的分配和释放请求。

~~~c
// mm.c  extend_heap：用一个新的空闲块扩展堆
static void *extend_heap(size_t words)
{
    char *bp;
    size_t size;

    /* Allocate an even number of words to maintain alignment */
    // Adjust the requested size to an even number of words to maintain alignment.
    // This is important because most architectures require data to be aligned.
    size = (words % 2) ? (words + 1) * WSIZE : words * WSIZE;
    
    // Extend the heap by the adjusted size. If the extension fails (mem_sbrk returns -1),
    // return NULL to indicate failure.
    if ((long)(bp = mem_sbrk(size)) == -1)
        return NULL;

    /* Initialize free block header/footer and the epilogue header */
    // Set up the header for the new free block. The size is set to the adjusted size,
    // and the allocation bit is set to 0 (indicating a free block).
    PUT(HDRP(bp), PACK(size, 0));         /* Free block header */

    // Similarly, set up the footer for the new free block. The footer has the same
    // size and allocation bit as the header.
    PUT(FTRP(bp), PACK(size, 0));         /* Free block footer */

    // Update the epilogue header of the heap to reflect the new end of the heap.
    // The epilogue header is always a zero-size block with the allocation bit set,
    // indicating the end of the heap.
    PUT(HDRP(NEXT_BLKP(bp)), PACK(0, 1)); /* New epilogue header */

    /* Coalesce if the previous block was free */
    // Try to merge this new free block with adjacent free blocks (if any) to
    // reduce fragmentation. The coalesce function handles the logic of merging.
    // It returns a pointer to the coalesced block (which may be the same as bp if no
    // coalescing occurred).
    return coalesce(bp);
}
~~~

`extend_heap` 函数会在两种不同的环境中被调用：
 1）当堆被初始化时；
 2）当 loc 不能找到一个合适的匹配块时。为了保持对齐，extend_heap 将请求大小向上舍入为最接近的 2 字（8 字节）的倍数，然后向内存系统请求额外的堆空间（第 7 ~ 9 行）。

`extend_heap` 函数的剩余部分（第 12 ~ 17 行）有点儿微妙。
堆开始于一个双字对齐的边界，并且每次对 extend_heap 的调用都返回一个块，该块的大小是双字的整数倍。
因此，对 mem_sbrk 的每次调用都返回一个双字对齐的内存片，紧跟在结尾块的头部后面。
这个头部变成了新的空闲块的头部（第 12 行），并且这个片的最后一个字变成了新的结尾块的头部（第 14 行）。
最后，在很可能出现的前一个堆以一个空闲块结束的情况中，我们调用 coalesce 函数来合并两个空闲块，并返回指向合并后的块的块指针（第 17 行）。 

